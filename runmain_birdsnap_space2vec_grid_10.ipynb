{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6a3f5aa7",
   "metadata": {},
   "source": [
    "**Put and run this notebook in the directory which contains TorchSpatial, because TorchSpatial will be used as a package. Relative imports are used within the package**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5433dc4d",
   "metadata": {},
   "source": [
    "**Model Training and Testing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "400ace9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim import Adam\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "15013057",
   "metadata": {},
   "outputs": [],
   "source": [
    "import TorchSpatial.modules.trainer as trainer\n",
    "from TorchSpatial.modules.encoder_selector import get_loc_encoder\n",
    "import TorchSpatial.modules.model as premade_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c50dc1c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/bolongtang/Downloads/TorchSpatial/modules/trainer.py\n"
     ]
    }
   ],
   "source": [
    "import importlib\n",
    "print(trainer.__file__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "669ae1f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'TorchSpatial.modules.model' from '/Users/bolongtang/Downloads/TorchSpatial/modules/model.py'>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# For easy reloading, bypassing cache in case trainer.py gets edited\n",
    "importlib.reload(trainer) \n",
    "\n",
    "importlib.reload(premade_models)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d979d3fa",
   "metadata": {},
   "source": [
    "**Import Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "385de89a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import TorchSpatial.utils.datasets as data_import\n",
    "import importlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f4c0523e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'TorchSpatial.utils.datasets' from '/Users/bolongtang/Downloads/TorchSpatial/utils/datasets.py'>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importlib.reload(data_import)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e33a882a",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\"dataset\": \"birdsnap\", \"meta_type\": \"orig_meta\", \"regress_dataset\": []}\n",
    "train_remove_invalid = True\n",
    "eval_remove_invalid = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d083fc6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading birdsnap_with_loc_2019.json - train\n",
      "   using meta data: orig_meta\n",
      "\t 46386 total entries\n",
      "\t 43426 entries with images\n",
      "\t 19133 entries with meta data\n",
      "Loading birdsnap_with_loc_2019.json - train\n",
      "   using meta data: orig_meta\n",
      "\t 46386 total entries\n",
      "\t 43426 entries with images\n",
      "\t 19133 entries with meta data\n"
     ]
    }
   ],
   "source": [
    "train_data = data_import.load_dataset(params = params,\n",
    "    eval_split = \"train\",\n",
    "    train_remove_invalid = train_remove_invalid,\n",
    "    eval_remove_invalid = eval_remove_invalid,\n",
    "    load_cnn_predictions=True,\n",
    "    load_cnn_features=True,\n",
    "    load_cnn_features_train=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c4e482cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading birdsnap_with_loc_2019.json - train\n",
      "   using meta data: orig_meta\n",
      "\t 46386 total entries\n",
      "\t 43426 entries with images\n",
      "\t 19133 entries with meta data\n",
      "Loading birdsnap_with_loc_2019.json - test\n",
      "   using meta data: orig_meta\n",
      "\t 2443 total entries\n",
      "\t 2262 entries with images\n",
      "\t 816 entries with meta data\n"
     ]
    }
   ],
   "source": [
    "test_data = data_import.load_dataset(params = params,\n",
    "    eval_split = \"test\",\n",
    "    train_remove_invalid = train_remove_invalid,\n",
    "    eval_remove_invalid = eval_remove_invalid,\n",
    "    load_cnn_predictions=True,\n",
    "    load_cnn_features=True,\n",
    "    load_cnn_features_train=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8dca1ace",
   "metadata": {},
   "outputs": [],
   "source": [
    "# - birdsnap dataset\n",
    "dataset = \"birdsnap\"\n",
    "task = \"Classification\"\n",
    "N = 19133\n",
    "device = \"cpu\"\n",
    "num_classes = 500 # birdsnap class count\n",
    "img_dim = loc_dim = embed_dim = 2048 # birdsnap embedding count\n",
    "coord_dim = 2 #lonlat\n",
    "\n",
    "img_tr = train_data[\"val_feats\"] # shape=(19133, 2048)\n",
    "loc_tr = train_data[\"val_locs\"] # shape=(19133, 2)\n",
    "y_tr = train_data[\"val_preds\"] # shape=(19133, 500)\n",
    "\n",
    "img_te = test_data[\"val_feats\"] # shape=(816, 2048)\n",
    "loc_te = test_data[\"val_locs\"] # shape=(816, 2)\n",
    "y_te = test_data[\"val_preds\"] # shape=(816, 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "971cb633",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(19133, 2048) (19133, 2) (19133, 500)\n"
     ]
    }
   ],
   "source": [
    "print(img_tr.shape, loc_tr.shape, y_tr.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2956bf8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(816, 2048) (816, 2) (816, 500)\n"
     ]
    }
   ],
   "source": [
    "print(img_te.shape, loc_te.shape, y_te.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0fea3507",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = list(zip(train_data[\"val_feats\"], train_data[\"val_locs\"], train_data[\"val_preds\"]))\n",
    "test_data  = list(zip(test_data[\"val_feats\"], test_data[\"val_locs\"], test_data[\"val_preds\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "398a5485",
   "metadata": {},
   "outputs": [],
   "source": [
    "# - Dataloader (loads image embeddings)\n",
    "train_loader = DataLoader(train_data, batch_size=32, shuffle=True)\n",
    "train_loader2 = DataLoader(train_data, batch_size=32, shuffle=True) # For demonstration only; used below to not iterate through the actual train_loader, which is an iterator and each row only be accessed once per refill\n",
    "test_loader  = DataLoader(test_data, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ce1ed806",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 2048]) <class 'torch.Tensor'> tensor([[0.1851, 0.0532, 0.2775,  ..., 0.1338, 1.2624, 0.4498],\n",
      "        [0.3632, 0.5042, 0.0191,  ..., 0.6604, 0.0580, 0.7077],\n",
      "        [0.1710, 0.3779, 0.0968,  ..., 0.2376, 0.7921, 1.1272],\n",
      "        ...,\n",
      "        [0.0679, 0.0562, 0.7301,  ..., 0.2016, 0.1728, 0.0412],\n",
      "        [0.2140, 0.3429, 0.0867,  ..., 0.0068, 0.5626, 0.0616],\n",
      "        [0.6310, 0.1920, 0.0062,  ..., 0.0628, 0.4519, 2.1073]])\n",
      "torch.Size([32, 2]) <class 'torch.Tensor'> tensor([[-122.4751,   37.8095],\n",
      "        [  17.6211,   59.8419],\n",
      "        [ -90.7098,   -0.3993],\n",
      "        [   9.5993,   52.8801],\n",
      "        [-121.3746,   38.3951],\n",
      "        [ -76.3279,   38.0480],\n",
      "        [ -83.9242,   39.3878],\n",
      "        [ -83.4506,   41.5058],\n",
      "        [ -99.1151,   26.5146],\n",
      "        [-110.8801,   31.7251],\n",
      "        [ -97.7631,   30.4610],\n",
      "        [ -92.6603,   47.1678],\n",
      "        [ -87.8515,   18.2137],\n",
      "        [-118.3077,   33.7495],\n",
      "        [ -75.3359,   37.9095],\n",
      "        [ -74.0052,   45.4860],\n",
      "        [ -91.6884,   44.0804],\n",
      "        [   4.5088,   51.9677],\n",
      "        [-117.9595,   34.1135],\n",
      "        [ -84.7925,   39.1236],\n",
      "        [ -89.8155,   13.5312],\n",
      "        [-122.6119,   48.4043],\n",
      "        [ -97.7125,   30.3285],\n",
      "        [ -96.8053,   32.7833],\n",
      "        [ -80.1614,   26.4885],\n",
      "        [ -19.0208,   63.4195],\n",
      "        [ -75.3463,   37.9443],\n",
      "        [  80.3163,   13.4169],\n",
      "        [-122.5264,   37.8953],\n",
      "        [-120.3547,   39.7567],\n",
      "        [-103.1846,   34.1429],\n",
      "        [-123.1872,   49.0996]])\n",
      "torch.Size([32, 500]) <class 'torch.Tensor'> tensor([[0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00],\n",
      "        ...,\n",
      "        [0.0000e+00, 0.0000e+00, 1.1119e-06,  ..., 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00]])\n"
     ]
    }
   ],
   "source": [
    "for img_b, loc_b, y_b in train_loader2:\n",
    "    print(img_b.shape, type(img_b), img_b) # Should be random floats\n",
    "    print(loc_b.shape, type(loc_b), loc_b) # lat [-90, 90] and lon [0, 360]\n",
    "    print(y_b.shape, type(y_b), y_b) # random ints [0, 500]\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5f19a9f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# - location encoder\n",
    "# Allowed: Space2Vec-grid, Space2Vec-theory, xyz, NeRF, Sphere2Vec-sphereC, Sphere2Vec-sphereC+, Sphere2Vec-sphereM, Sphere2Vec-sphereM+, Sphere2Vec-dfs, rbf, rff, wrap, wrap_ffn, tile_ffn\n",
    "# overrides is a dictionary that allows overriding specific params. \n",
    "# ex. loc_encoder = get_loc_encoder(name = \"Space2Vec-grid\", overrides = {\"max_radius\":7800, \"min_radius\":15, \"spa_embed_dim\":2048, \"device\": device})\n",
    "loc_encoder = get_loc_encoder(name = \"Space2Vec-grid\", overrides = {\"coord_dim\": coord_dim, \"spa_embed_dim\": loc_dim, \"device\": device}) # \"device\": device is needed if you defined device = 'cpu' above and don't have cuda setup to prevent \"AssertionError: Torch not compiled with CUDA enabled\", because the default is device=\"cuda\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2868bf79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# - model\n",
    "decoder = premade_models.ThreeLayerMLP(input_dim = embed_dim, hidden_dim = 1024, category_count = num_classes).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5f552086",
   "metadata": {},
   "outputs": [],
   "source": [
    "# - Criterion\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# - Optimizer\n",
    "optimizer = Adam(params = list(loc_encoder.ffn.parameters()) + list(decoder.parameters()), lr = 1e-3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b7fd5dec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 1, batch    10] loss: 6.214\n",
      "[epoch 1, batch    20] loss: 6.210\n",
      "[epoch 1, batch    30] loss: 6.195\n",
      "[epoch 1, batch    40] loss: 6.158\n",
      "[epoch 1, batch    50] loss: 6.124\n",
      "[epoch 1, batch    60] loss: 5.997\n",
      "[epoch 1, batch    70] loss: 5.800\n",
      "[epoch 1, batch    80] loss: 5.478\n",
      "[epoch 1, batch    90] loss: 5.078\n",
      "[epoch 1, batch   100] loss: 4.840\n",
      "[epoch 1, batch   110] loss: 4.548\n",
      "[epoch 1, batch   120] loss: 4.007\n",
      "[epoch 1, batch   130] loss: 3.493\n",
      "[epoch 1, batch   140] loss: 3.290\n",
      "[epoch 1, batch   150] loss: 2.820\n",
      "[epoch 1, batch   160] loss: 2.601\n",
      "[epoch 1, batch   170] loss: 2.402\n",
      "[epoch 1, batch   180] loss: 2.285\n",
      "[epoch 1, batch   190] loss: 2.209\n",
      "[epoch 1, batch   200] loss: 1.978\n",
      "[epoch 1, batch   210] loss: 1.930\n",
      "[epoch 1, batch   220] loss: 1.844\n",
      "[epoch 1, batch   230] loss: 1.638\n",
      "[epoch 1, batch   240] loss: 1.657\n",
      "[epoch 1, batch   250] loss: 1.730\n",
      "[epoch 1, batch   260] loss: 1.584\n",
      "[epoch 1, batch   270] loss: 1.519\n",
      "[epoch 1, batch   280] loss: 1.263\n",
      "[epoch 1, batch   290] loss: 1.499\n",
      "[epoch 1, batch   300] loss: 1.262\n",
      "[epoch 1, batch   310] loss: 1.607\n",
      "[epoch 1, batch   320] loss: 1.313\n",
      "[epoch 1, batch   330] loss: 1.336\n",
      "[epoch 1, batch   340] loss: 1.389\n",
      "[epoch 1, batch   350] loss: 1.348\n",
      "[epoch 1, batch   360] loss: 1.161\n",
      "[epoch 1, batch   370] loss: 1.116\n",
      "[epoch 1, batch   380] loss: 1.338\n",
      "[epoch 1, batch   390] loss: 1.176\n",
      "[epoch 1, batch   400] loss: 1.185\n",
      "[epoch 1, batch   410] loss: 1.198\n",
      "[epoch 1, batch   420] loss: 1.157\n",
      "[epoch 1, batch   430] loss: 1.149\n",
      "[epoch 1, batch   440] loss: 1.213\n",
      "[epoch 1, batch   450] loss: 1.117\n",
      "[epoch 1, batch   460] loss: 1.105\n",
      "[epoch 1, batch   470] loss: 1.247\n",
      "[epoch 1, batch   480] loss: 1.110\n",
      "[epoch 1, batch   490] loss: 1.025\n",
      "[epoch 1, batch   500] loss: 1.142\n",
      "[epoch 1, batch   510] loss: 0.971\n",
      "[epoch 1, batch   520] loss: 1.073\n",
      "[epoch 1, batch   530] loss: 1.075\n",
      "[epoch 1, batch   540] loss: 1.020\n",
      "[epoch 1, batch   550] loss: 1.051\n",
      "[epoch 1, batch   560] loss: 1.025\n",
      "[epoch 1, batch   570] loss: 1.126\n",
      "[epoch 1, batch   580] loss: 1.018\n",
      "[epoch 1, batch   590] loss: 1.127\n",
      "[epoch 2, batch    10] loss: 0.957\n",
      "[epoch 2, batch    20] loss: 0.992\n",
      "[epoch 2, batch    30] loss: 0.895\n",
      "[epoch 2, batch    40] loss: 0.830\n",
      "[epoch 2, batch    50] loss: 0.933\n",
      "[epoch 2, batch    60] loss: 0.955\n",
      "[epoch 2, batch    70] loss: 0.854\n",
      "[epoch 2, batch    80] loss: 1.094\n",
      "[epoch 2, batch    90] loss: 0.911\n",
      "[epoch 2, batch   100] loss: 0.953\n",
      "[epoch 2, batch   110] loss: 1.035\n",
      "[epoch 2, batch   120] loss: 1.097\n",
      "[epoch 2, batch   130] loss: 0.843\n",
      "[epoch 2, batch   140] loss: 1.053\n",
      "[epoch 2, batch   150] loss: 0.876\n",
      "[epoch 2, batch   160] loss: 0.970\n",
      "[epoch 2, batch   170] loss: 0.997\n",
      "[epoch 2, batch   180] loss: 0.939\n",
      "[epoch 2, batch   190] loss: 0.877\n",
      "[epoch 2, batch   200] loss: 0.860\n",
      "[epoch 2, batch   210] loss: 0.913\n",
      "[epoch 2, batch   220] loss: 0.976\n",
      "[epoch 2, batch   230] loss: 0.833\n",
      "[epoch 2, batch   240] loss: 0.976\n",
      "[epoch 2, batch   250] loss: 0.967\n",
      "[epoch 2, batch   260] loss: 0.944\n",
      "[epoch 2, batch   270] loss: 0.747\n",
      "[epoch 2, batch   280] loss: 0.792\n",
      "[epoch 2, batch   290] loss: 0.874\n",
      "[epoch 2, batch   300] loss: 0.952\n",
      "[epoch 2, batch   310] loss: 0.935\n",
      "[epoch 2, batch   320] loss: 0.865\n",
      "[epoch 2, batch   330] loss: 0.770\n",
      "[epoch 2, batch   340] loss: 0.911\n",
      "[epoch 2, batch   350] loss: 0.925\n",
      "[epoch 2, batch   360] loss: 0.877\n",
      "[epoch 2, batch   370] loss: 0.803\n",
      "[epoch 2, batch   380] loss: 0.790\n",
      "[epoch 2, batch   390] loss: 0.758\n",
      "[epoch 2, batch   400] loss: 0.920\n",
      "[epoch 2, batch   410] loss: 0.829\n",
      "[epoch 2, batch   420] loss: 0.857\n",
      "[epoch 2, batch   430] loss: 1.012\n",
      "[epoch 2, batch   440] loss: 0.875\n",
      "[epoch 2, batch   450] loss: 0.887\n",
      "[epoch 2, batch   460] loss: 0.705\n",
      "[epoch 2, batch   470] loss: 0.911\n",
      "[epoch 2, batch   480] loss: 0.742\n",
      "[epoch 2, batch   490] loss: 0.917\n",
      "[epoch 2, batch   500] loss: 0.884\n",
      "[epoch 2, batch   510] loss: 0.889\n",
      "[epoch 2, batch   520] loss: 0.852\n",
      "[epoch 2, batch   530] loss: 1.013\n",
      "[epoch 2, batch   540] loss: 1.031\n",
      "[epoch 2, batch   550] loss: 0.861\n",
      "[epoch 2, batch   560] loss: 0.916\n",
      "[epoch 2, batch   570] loss: 0.813\n",
      "[epoch 2, batch   580] loss: 0.901\n",
      "[epoch 2, batch   590] loss: 0.852\n",
      "[epoch 3, batch    10] loss: 0.962\n",
      "[epoch 3, batch    20] loss: 0.936\n",
      "[epoch 3, batch    30] loss: 0.663\n",
      "[epoch 3, batch    40] loss: 0.840\n",
      "[epoch 3, batch    50] loss: 0.783\n",
      "[epoch 3, batch    60] loss: 0.875\n",
      "[epoch 3, batch    70] loss: 0.803\n",
      "[epoch 3, batch    80] loss: 0.683\n",
      "[epoch 3, batch    90] loss: 0.879\n",
      "[epoch 3, batch   100] loss: 0.840\n",
      "[epoch 3, batch   110] loss: 0.738\n",
      "[epoch 3, batch   120] loss: 0.736\n",
      "[epoch 3, batch   130] loss: 0.799\n",
      "[epoch 3, batch   140] loss: 0.902\n",
      "[epoch 3, batch   150] loss: 0.863\n",
      "[epoch 3, batch   160] loss: 0.757\n",
      "[epoch 3, batch   170] loss: 0.782\n",
      "[epoch 3, batch   180] loss: 0.762\n",
      "[epoch 3, batch   190] loss: 0.781\n",
      "[epoch 3, batch   200] loss: 0.788\n",
      "[epoch 3, batch   210] loss: 0.700\n",
      "[epoch 3, batch   220] loss: 0.833\n",
      "[epoch 3, batch   230] loss: 0.900\n",
      "[epoch 3, batch   240] loss: 0.763\n",
      "[epoch 3, batch   250] loss: 0.792\n",
      "[epoch 3, batch   260] loss: 0.882\n",
      "[epoch 3, batch   270] loss: 0.806\n",
      "[epoch 3, batch   280] loss: 0.630\n",
      "[epoch 3, batch   290] loss: 0.896\n",
      "[epoch 3, batch   300] loss: 0.840\n",
      "[epoch 3, batch   310] loss: 0.747\n",
      "[epoch 3, batch   320] loss: 0.637\n",
      "[epoch 3, batch   330] loss: 0.700\n",
      "[epoch 3, batch   340] loss: 0.744\n",
      "[epoch 3, batch   350] loss: 0.847\n",
      "[epoch 3, batch   360] loss: 0.746\n",
      "[epoch 3, batch   370] loss: 0.739\n",
      "[epoch 3, batch   380] loss: 0.914\n",
      "[epoch 3, batch   390] loss: 0.707\n",
      "[epoch 3, batch   400] loss: 0.673\n",
      "[epoch 3, batch   410] loss: 0.738\n",
      "[epoch 3, batch   420] loss: 0.875\n",
      "[epoch 3, batch   430] loss: 0.873\n",
      "[epoch 3, batch   440] loss: 0.817\n",
      "[epoch 3, batch   450] loss: 0.870\n",
      "[epoch 3, batch   460] loss: 0.837\n",
      "[epoch 3, batch   470] loss: 0.841\n",
      "[epoch 3, batch   480] loss: 0.693\n",
      "[epoch 3, batch   490] loss: 0.745\n",
      "[epoch 3, batch   500] loss: 0.744\n",
      "[epoch 3, batch   510] loss: 0.708\n",
      "[epoch 3, batch   520] loss: 0.785\n",
      "[epoch 3, batch   530] loss: 0.783\n",
      "[epoch 3, batch   540] loss: 0.783\n",
      "[epoch 3, batch   550] loss: 0.833\n",
      "[epoch 3, batch   560] loss: 0.708\n",
      "[epoch 3, batch   570] loss: 0.835\n",
      "[epoch 3, batch   580] loss: 0.799\n",
      "[epoch 3, batch   590] loss: 0.751\n",
      "[epoch 4, batch    10] loss: 0.777\n",
      "[epoch 4, batch    20] loss: 0.764\n",
      "[epoch 4, batch    30] loss: 0.744\n",
      "[epoch 4, batch    40] loss: 0.685\n",
      "[epoch 4, batch    50] loss: 0.706\n",
      "[epoch 4, batch    60] loss: 0.799\n",
      "[epoch 4, batch    70] loss: 0.603\n",
      "[epoch 4, batch    80] loss: 0.822\n",
      "[epoch 4, batch    90] loss: 0.723\n",
      "[epoch 4, batch   100] loss: 0.632\n",
      "[epoch 4, batch   110] loss: 0.834\n",
      "[epoch 4, batch   120] loss: 0.723\n",
      "[epoch 4, batch   130] loss: 0.780\n",
      "[epoch 4, batch   140] loss: 0.791\n",
      "[epoch 4, batch   150] loss: 0.745\n",
      "[epoch 4, batch   160] loss: 0.662\n",
      "[epoch 4, batch   170] loss: 0.720\n",
      "[epoch 4, batch   180] loss: 0.820\n",
      "[epoch 4, batch   190] loss: 0.718\n",
      "[epoch 4, batch   200] loss: 0.785\n",
      "[epoch 4, batch   210] loss: 0.769\n",
      "[epoch 4, batch   220] loss: 0.713\n",
      "[epoch 4, batch   230] loss: 0.799\n",
      "[epoch 4, batch   240] loss: 0.788\n",
      "[epoch 4, batch   250] loss: 0.744\n",
      "[epoch 4, batch   260] loss: 0.698\n",
      "[epoch 4, batch   270] loss: 0.713\n",
      "[epoch 4, batch   280] loss: 0.702\n",
      "[epoch 4, batch   290] loss: 0.804\n",
      "[epoch 4, batch   300] loss: 0.656\n",
      "[epoch 4, batch   310] loss: 0.700\n",
      "[epoch 4, batch   320] loss: 0.689\n",
      "[epoch 4, batch   330] loss: 0.787\n",
      "[epoch 4, batch   340] loss: 0.604\n",
      "[epoch 4, batch   350] loss: 0.714\n",
      "[epoch 4, batch   360] loss: 0.708\n",
      "[epoch 4, batch   370] loss: 0.736\n",
      "[epoch 4, batch   380] loss: 0.637\n",
      "[epoch 4, batch   390] loss: 0.683\n",
      "[epoch 4, batch   400] loss: 0.708\n",
      "[epoch 4, batch   410] loss: 0.728\n",
      "[epoch 4, batch   420] loss: 0.808\n",
      "[epoch 4, batch   430] loss: 0.820\n",
      "[epoch 4, batch   440] loss: 0.824\n",
      "[epoch 4, batch   450] loss: 0.731\n",
      "[epoch 4, batch   460] loss: 0.764\n",
      "[epoch 4, batch   470] loss: 0.657\n",
      "[epoch 4, batch   480] loss: 0.788\n",
      "[epoch 4, batch   490] loss: 0.794\n",
      "[epoch 4, batch   500] loss: 0.770\n",
      "[epoch 4, batch   510] loss: 0.693\n",
      "[epoch 4, batch   520] loss: 0.810\n",
      "[epoch 4, batch   530] loss: 0.691\n",
      "[epoch 4, batch   540] loss: 0.786\n",
      "[epoch 4, batch   550] loss: 0.842\n",
      "[epoch 4, batch   560] loss: 0.706\n",
      "[epoch 4, batch   570] loss: 0.580\n",
      "[epoch 4, batch   580] loss: 0.732\n",
      "[epoch 4, batch   590] loss: 0.830\n",
      "[epoch 5, batch    10] loss: 0.688\n",
      "[epoch 5, batch    20] loss: 0.760\n",
      "[epoch 5, batch    30] loss: 0.637\n",
      "[epoch 5, batch    40] loss: 0.639\n",
      "[epoch 5, batch    50] loss: 0.759\n",
      "[epoch 5, batch    60] loss: 0.727\n",
      "[epoch 5, batch    70] loss: 0.716\n",
      "[epoch 5, batch    80] loss: 0.637\n",
      "[epoch 5, batch    90] loss: 0.746\n",
      "[epoch 5, batch   100] loss: 0.636\n",
      "[epoch 5, batch   110] loss: 0.757\n",
      "[epoch 5, batch   120] loss: 0.716\n",
      "[epoch 5, batch   130] loss: 0.730\n",
      "[epoch 5, batch   140] loss: 0.702\n",
      "[epoch 5, batch   150] loss: 0.717\n",
      "[epoch 5, batch   160] loss: 0.826\n",
      "[epoch 5, batch   170] loss: 0.677\n",
      "[epoch 5, batch   180] loss: 0.702\n",
      "[epoch 5, batch   190] loss: 0.693\n",
      "[epoch 5, batch   200] loss: 0.657\n",
      "[epoch 5, batch   210] loss: 0.632\n",
      "[epoch 5, batch   220] loss: 0.650\n",
      "[epoch 5, batch   230] loss: 0.659\n",
      "[epoch 5, batch   240] loss: 0.775\n",
      "[epoch 5, batch   250] loss: 0.707\n",
      "[epoch 5, batch   260] loss: 0.752\n",
      "[epoch 5, batch   270] loss: 0.682\n",
      "[epoch 5, batch   280] loss: 0.609\n",
      "[epoch 5, batch   290] loss: 0.620\n",
      "[epoch 5, batch   300] loss: 0.698\n",
      "[epoch 5, batch   310] loss: 0.653\n",
      "[epoch 5, batch   320] loss: 0.653\n",
      "[epoch 5, batch   330] loss: 0.759\n",
      "[epoch 5, batch   340] loss: 0.716\n",
      "[epoch 5, batch   350] loss: 0.772\n",
      "[epoch 5, batch   360] loss: 0.788\n",
      "[epoch 5, batch   370] loss: 0.697\n",
      "[epoch 5, batch   380] loss: 0.780\n",
      "[epoch 5, batch   390] loss: 0.733\n",
      "[epoch 5, batch   400] loss: 0.787\n",
      "[epoch 5, batch   410] loss: 0.626\n",
      "[epoch 5, batch   420] loss: 0.665\n",
      "[epoch 5, batch   430] loss: 0.677\n",
      "[epoch 5, batch   440] loss: 0.741\n",
      "[epoch 5, batch   450] loss: 0.685\n",
      "[epoch 5, batch   460] loss: 0.632\n",
      "[epoch 5, batch   470] loss: 0.702\n",
      "[epoch 5, batch   480] loss: 0.636\n",
      "[epoch 5, batch   490] loss: 0.632\n",
      "[epoch 5, batch   500] loss: 0.756\n",
      "[epoch 5, batch   510] loss: 0.747\n",
      "[epoch 5, batch   520] loss: 0.711\n",
      "[epoch 5, batch   530] loss: 0.769\n",
      "[epoch 5, batch   540] loss: 0.745\n",
      "[epoch 5, batch   550] loss: 0.751\n",
      "[epoch 5, batch   560] loss: 0.688\n",
      "[epoch 5, batch   570] loss: 0.608\n",
      "[epoch 5, batch   580] loss: 0.717\n",
      "[epoch 5, batch   590] loss: 0.782\n",
      "[epoch 6, batch    10] loss: 0.673\n",
      "[epoch 6, batch    20] loss: 0.748\n",
      "[epoch 6, batch    30] loss: 0.669\n",
      "[epoch 6, batch    40] loss: 0.724\n",
      "[epoch 6, batch    50] loss: 0.654\n",
      "[epoch 6, batch    60] loss: 0.594\n",
      "[epoch 6, batch    70] loss: 0.723\n",
      "[epoch 6, batch    80] loss: 0.653\n",
      "[epoch 6, batch    90] loss: 0.688\n",
      "[epoch 6, batch   100] loss: 0.608\n",
      "[epoch 6, batch   110] loss: 0.708\n",
      "[epoch 6, batch   120] loss: 0.704\n",
      "[epoch 6, batch   130] loss: 0.655\n",
      "[epoch 6, batch   140] loss: 0.671\n",
      "[epoch 6, batch   150] loss: 0.656\n",
      "[epoch 6, batch   160] loss: 0.658\n",
      "[epoch 6, batch   170] loss: 0.600\n",
      "[epoch 6, batch   180] loss: 0.725\n",
      "[epoch 6, batch   190] loss: 0.777\n",
      "[epoch 6, batch   200] loss: 0.605\n",
      "[epoch 6, batch   210] loss: 0.707\n",
      "[epoch 6, batch   220] loss: 0.665\n",
      "[epoch 6, batch   230] loss: 0.694\n",
      "[epoch 6, batch   240] loss: 0.557\n",
      "[epoch 6, batch   250] loss: 0.595\n",
      "[epoch 6, batch   260] loss: 0.700\n",
      "[epoch 6, batch   270] loss: 0.695\n",
      "[epoch 6, batch   280] loss: 0.732\n",
      "[epoch 6, batch   290] loss: 0.609\n",
      "[epoch 6, batch   300] loss: 0.524\n",
      "[epoch 6, batch   310] loss: 0.819\n",
      "[epoch 6, batch   320] loss: 0.750\n",
      "[epoch 6, batch   330] loss: 0.639\n",
      "[epoch 6, batch   340] loss: 0.659\n",
      "[epoch 6, batch   350] loss: 0.669\n",
      "[epoch 6, batch   360] loss: 0.642\n",
      "[epoch 6, batch   370] loss: 0.760\n",
      "[epoch 6, batch   380] loss: 0.627\n",
      "[epoch 6, batch   390] loss: 0.748\n",
      "[epoch 6, batch   400] loss: 0.711\n",
      "[epoch 6, batch   410] loss: 0.628\n",
      "[epoch 6, batch   420] loss: 0.655\n",
      "[epoch 6, batch   430] loss: 0.777\n",
      "[epoch 6, batch   440] loss: 0.648\n",
      "[epoch 6, batch   450] loss: 0.695\n",
      "[epoch 6, batch   460] loss: 0.641\n",
      "[epoch 6, batch   470] loss: 0.666\n",
      "[epoch 6, batch   480] loss: 0.689\n",
      "[epoch 6, batch   490] loss: 0.702\n",
      "[epoch 6, batch   500] loss: 0.689\n",
      "[epoch 6, batch   510] loss: 0.557\n",
      "[epoch 6, batch   520] loss: 0.708\n",
      "[epoch 6, batch   530] loss: 0.843\n",
      "[epoch 6, batch   540] loss: 0.709\n",
      "[epoch 6, batch   550] loss: 0.682\n",
      "[epoch 6, batch   560] loss: 0.760\n",
      "[epoch 6, batch   570] loss: 0.708\n",
      "[epoch 6, batch   580] loss: 0.659\n",
      "[epoch 6, batch   590] loss: 0.641\n",
      "[epoch 7, batch    10] loss: 0.669\n",
      "[epoch 7, batch    20] loss: 0.649\n",
      "[epoch 7, batch    30] loss: 0.657\n",
      "[epoch 7, batch    40] loss: 0.692\n",
      "[epoch 7, batch    50] loss: 0.511\n",
      "[epoch 7, batch    60] loss: 0.569\n",
      "[epoch 7, batch    70] loss: 0.625\n",
      "[epoch 7, batch    80] loss: 0.723\n",
      "[epoch 7, batch    90] loss: 0.686\n",
      "[epoch 7, batch   100] loss: 0.593\n",
      "[epoch 7, batch   110] loss: 0.654\n",
      "[epoch 7, batch   120] loss: 0.724\n",
      "[epoch 7, batch   130] loss: 0.628\n",
      "[epoch 7, batch   140] loss: 0.782\n",
      "[epoch 7, batch   150] loss: 0.783\n",
      "[epoch 7, batch   160] loss: 0.616\n",
      "[epoch 7, batch   170] loss: 0.645\n",
      "[epoch 7, batch   180] loss: 0.718\n",
      "[epoch 7, batch   190] loss: 0.577\n",
      "[epoch 7, batch   200] loss: 0.698\n",
      "[epoch 7, batch   210] loss: 0.749\n",
      "[epoch 7, batch   220] loss: 0.633\n",
      "[epoch 7, batch   230] loss: 0.711\n",
      "[epoch 7, batch   240] loss: 0.707\n",
      "[epoch 7, batch   250] loss: 0.600\n",
      "[epoch 7, batch   260] loss: 0.544\n",
      "[epoch 7, batch   270] loss: 0.546\n",
      "[epoch 7, batch   280] loss: 0.654\n",
      "[epoch 7, batch   290] loss: 0.770\n",
      "[epoch 7, batch   300] loss: 0.702\n",
      "[epoch 7, batch   310] loss: 0.590\n",
      "[epoch 7, batch   320] loss: 0.632\n",
      "[epoch 7, batch   330] loss: 0.746\n",
      "[epoch 7, batch   340] loss: 0.628\n",
      "[epoch 7, batch   350] loss: 0.586\n",
      "[epoch 7, batch   360] loss: 0.741\n",
      "[epoch 7, batch   370] loss: 0.634\n",
      "[epoch 7, batch   380] loss: 0.696\n",
      "[epoch 7, batch   390] loss: 0.702\n",
      "[epoch 7, batch   400] loss: 0.815\n",
      "[epoch 7, batch   410] loss: 0.730\n",
      "[epoch 7, batch   420] loss: 0.718\n",
      "[epoch 7, batch   430] loss: 0.696\n",
      "[epoch 7, batch   440] loss: 0.733\n",
      "[epoch 7, batch   450] loss: 0.643\n",
      "[epoch 7, batch   460] loss: 0.781\n",
      "[epoch 7, batch   470] loss: 0.770\n",
      "[epoch 7, batch   480] loss: 0.663\n",
      "[epoch 7, batch   490] loss: 0.728\n",
      "[epoch 7, batch   500] loss: 0.764\n",
      "[epoch 7, batch   510] loss: 0.709\n",
      "[epoch 7, batch   520] loss: 0.694\n",
      "[epoch 7, batch   530] loss: 0.701\n",
      "[epoch 7, batch   540] loss: 0.780\n",
      "[epoch 7, batch   550] loss: 0.617\n",
      "[epoch 7, batch   560] loss: 0.614\n",
      "[epoch 7, batch   570] loss: 0.701\n",
      "[epoch 7, batch   580] loss: 0.783\n",
      "[epoch 7, batch   590] loss: 0.606\n",
      "[epoch 8, batch    10] loss: 0.670\n",
      "[epoch 8, batch    20] loss: 0.788\n",
      "[epoch 8, batch    30] loss: 0.645\n",
      "[epoch 8, batch    40] loss: 0.726\n",
      "[epoch 8, batch    50] loss: 0.610\n",
      "[epoch 8, batch    60] loss: 0.579\n",
      "[epoch 8, batch    70] loss: 0.595\n",
      "[epoch 8, batch    80] loss: 0.735\n",
      "[epoch 8, batch    90] loss: 0.735\n",
      "[epoch 8, batch   100] loss: 0.623\n",
      "[epoch 8, batch   110] loss: 0.766\n",
      "[epoch 8, batch   120] loss: 0.657\n",
      "[epoch 8, batch   130] loss: 0.545\n",
      "[epoch 8, batch   140] loss: 0.685\n",
      "[epoch 8, batch   150] loss: 0.710\n",
      "[epoch 8, batch   160] loss: 0.678\n",
      "[epoch 8, batch   170] loss: 0.611\n",
      "[epoch 8, batch   180] loss: 0.703\n",
      "[epoch 8, batch   190] loss: 0.710\n",
      "[epoch 8, batch   200] loss: 0.562\n",
      "[epoch 8, batch   210] loss: 0.542\n",
      "[epoch 8, batch   220] loss: 0.587\n",
      "[epoch 8, batch   230] loss: 0.600\n",
      "[epoch 8, batch   240] loss: 0.586\n",
      "[epoch 8, batch   250] loss: 0.662\n",
      "[epoch 8, batch   260] loss: 0.613\n",
      "[epoch 8, batch   270] loss: 0.615\n",
      "[epoch 8, batch   280] loss: 0.684\n",
      "[epoch 8, batch   290] loss: 0.579\n",
      "[epoch 8, batch   300] loss: 0.620\n",
      "[epoch 8, batch   310] loss: 0.660\n",
      "[epoch 8, batch   320] loss: 0.642\n",
      "[epoch 8, batch   330] loss: 0.595\n",
      "[epoch 8, batch   340] loss: 0.610\n",
      "[epoch 8, batch   350] loss: 0.731\n",
      "[epoch 8, batch   360] loss: 0.640\n",
      "[epoch 8, batch   370] loss: 0.725\n",
      "[epoch 8, batch   380] loss: 0.656\n",
      "[epoch 8, batch   390] loss: 0.755\n",
      "[epoch 8, batch   400] loss: 0.611\n",
      "[epoch 8, batch   410] loss: 0.703\n",
      "[epoch 8, batch   420] loss: 0.602\n",
      "[epoch 8, batch   430] loss: 0.545\n",
      "[epoch 8, batch   440] loss: 0.646\n",
      "[epoch 8, batch   450] loss: 0.598\n",
      "[epoch 8, batch   460] loss: 0.802\n",
      "[epoch 8, batch   470] loss: 0.727\n",
      "[epoch 8, batch   480] loss: 0.700\n",
      "[epoch 8, batch   490] loss: 0.662\n",
      "[epoch 8, batch   500] loss: 0.646\n",
      "[epoch 8, batch   510] loss: 0.608\n",
      "[epoch 8, batch   520] loss: 0.744\n",
      "[epoch 8, batch   530] loss: 0.588\n",
      "[epoch 8, batch   540] loss: 0.668\n",
      "[epoch 8, batch   550] loss: 0.574\n",
      "[epoch 8, batch   560] loss: 0.644\n",
      "[epoch 8, batch   570] loss: 0.612\n",
      "[epoch 8, batch   580] loss: 0.637\n",
      "[epoch 8, batch   590] loss: 0.575\n",
      "[epoch 9, batch    10] loss: 0.701\n",
      "[epoch 9, batch    20] loss: 0.678\n",
      "[epoch 9, batch    30] loss: 0.607\n",
      "[epoch 9, batch    40] loss: 0.614\n",
      "[epoch 9, batch    50] loss: 0.665\n",
      "[epoch 9, batch    60] loss: 0.698\n",
      "[epoch 9, batch    70] loss: 0.646\n",
      "[epoch 9, batch    80] loss: 0.610\n",
      "[epoch 9, batch    90] loss: 0.745\n",
      "[epoch 9, batch   100] loss: 0.632\n",
      "[epoch 9, batch   110] loss: 0.735\n",
      "[epoch 9, batch   120] loss: 0.518\n",
      "[epoch 9, batch   130] loss: 0.622\n",
      "[epoch 9, batch   140] loss: 0.520\n",
      "[epoch 9, batch   150] loss: 0.655\n",
      "[epoch 9, batch   160] loss: 0.678\n",
      "[epoch 9, batch   170] loss: 0.678\n",
      "[epoch 9, batch   180] loss: 0.600\n",
      "[epoch 9, batch   190] loss: 0.674\n",
      "[epoch 9, batch   200] loss: 0.712\n",
      "[epoch 9, batch   210] loss: 0.643\n",
      "[epoch 9, batch   220] loss: 0.689\n",
      "[epoch 9, batch   230] loss: 0.671\n",
      "[epoch 9, batch   240] loss: 0.608\n",
      "[epoch 9, batch   250] loss: 0.613\n",
      "[epoch 9, batch   260] loss: 0.564\n",
      "[epoch 9, batch   270] loss: 0.661\n",
      "[epoch 9, batch   280] loss: 0.542\n",
      "[epoch 9, batch   290] loss: 0.687\n",
      "[epoch 9, batch   300] loss: 0.702\n",
      "[epoch 9, batch   310] loss: 0.740\n",
      "[epoch 9, batch   320] loss: 0.570\n",
      "[epoch 9, batch   330] loss: 0.604\n",
      "[epoch 9, batch   340] loss: 0.585\n",
      "[epoch 9, batch   350] loss: 0.659\n",
      "[epoch 9, batch   360] loss: 0.684\n",
      "[epoch 9, batch   370] loss: 0.622\n",
      "[epoch 9, batch   380] loss: 0.599\n",
      "[epoch 9, batch   390] loss: 0.512\n",
      "[epoch 9, batch   400] loss: 0.690\n",
      "[epoch 9, batch   410] loss: 0.761\n",
      "[epoch 9, batch   420] loss: 0.575\n",
      "[epoch 9, batch   430] loss: 0.608\n",
      "[epoch 9, batch   440] loss: 0.670\n",
      "[epoch 9, batch   450] loss: 0.672\n",
      "[epoch 9, batch   460] loss: 0.579\n",
      "[epoch 9, batch   470] loss: 0.698\n",
      "[epoch 9, batch   480] loss: 0.549\n",
      "[epoch 9, batch   490] loss: 0.550\n",
      "[epoch 9, batch   500] loss: 0.622\n",
      "[epoch 9, batch   510] loss: 0.620\n",
      "[epoch 9, batch   520] loss: 0.776\n",
      "[epoch 9, batch   530] loss: 0.602\n",
      "[epoch 9, batch   540] loss: 0.589\n",
      "[epoch 9, batch   550] loss: 0.620\n",
      "[epoch 9, batch   560] loss: 0.703\n",
      "[epoch 9, batch   570] loss: 0.636\n",
      "[epoch 9, batch   580] loss: 0.707\n",
      "[epoch 9, batch   590] loss: 0.719\n",
      "[epoch 10, batch    10] loss: 0.618\n",
      "[epoch 10, batch    20] loss: 0.792\n",
      "[epoch 10, batch    30] loss: 0.643\n",
      "[epoch 10, batch    40] loss: 0.677\n",
      "[epoch 10, batch    50] loss: 0.661\n",
      "[epoch 10, batch    60] loss: 0.540\n",
      "[epoch 10, batch    70] loss: 0.756\n",
      "[epoch 10, batch    80] loss: 0.597\n",
      "[epoch 10, batch    90] loss: 0.626\n",
      "[epoch 10, batch   100] loss: 0.786\n",
      "[epoch 10, batch   110] loss: 0.570\n",
      "[epoch 10, batch   120] loss: 0.585\n",
      "[epoch 10, batch   130] loss: 0.660\n",
      "[epoch 10, batch   140] loss: 0.737\n",
      "[epoch 10, batch   150] loss: 0.618\n",
      "[epoch 10, batch   160] loss: 0.586\n",
      "[epoch 10, batch   170] loss: 0.788\n",
      "[epoch 10, batch   180] loss: 0.525\n",
      "[epoch 10, batch   190] loss: 0.567\n",
      "[epoch 10, batch   200] loss: 0.563\n",
      "[epoch 10, batch   210] loss: 0.675\n",
      "[epoch 10, batch   220] loss: 0.578\n",
      "[epoch 10, batch   230] loss: 0.585\n",
      "[epoch 10, batch   240] loss: 0.742\n",
      "[epoch 10, batch   250] loss: 0.574\n",
      "[epoch 10, batch   260] loss: 0.573\n",
      "[epoch 10, batch   270] loss: 0.646\n",
      "[epoch 10, batch   280] loss: 0.625\n",
      "[epoch 10, batch   290] loss: 0.672\n",
      "[epoch 10, batch   300] loss: 0.608\n",
      "[epoch 10, batch   310] loss: 0.655\n",
      "[epoch 10, batch   320] loss: 0.558\n",
      "[epoch 10, batch   330] loss: 0.683\n",
      "[epoch 10, batch   340] loss: 0.585\n",
      "[epoch 10, batch   350] loss: 0.729\n",
      "[epoch 10, batch   360] loss: 0.552\n",
      "[epoch 10, batch   370] loss: 0.609\n",
      "[epoch 10, batch   380] loss: 0.683\n",
      "[epoch 10, batch   390] loss: 0.712\n",
      "[epoch 10, batch   400] loss: 0.630\n",
      "[epoch 10, batch   410] loss: 0.461\n",
      "[epoch 10, batch   420] loss: 0.589\n",
      "[epoch 10, batch   430] loss: 0.647\n",
      "[epoch 10, batch   440] loss: 0.666\n",
      "[epoch 10, batch   450] loss: 0.563\n",
      "[epoch 10, batch   460] loss: 0.733\n",
      "[epoch 10, batch   470] loss: 0.605\n",
      "[epoch 10, batch   480] loss: 0.533\n",
      "[epoch 10, batch   490] loss: 0.553\n",
      "[epoch 10, batch   500] loss: 0.673\n",
      "[epoch 10, batch   510] loss: 0.578\n",
      "[epoch 10, batch   520] loss: 0.700\n",
      "[epoch 10, batch   530] loss: 0.593\n",
      "[epoch 10, batch   540] loss: 0.679\n",
      "[epoch 10, batch   550] loss: 0.568\n",
      "[epoch 10, batch   560] loss: 0.608\n",
      "[epoch 10, batch   570] loss: 0.608\n",
      "[epoch 10, batch   580] loss: 0.503\n",
      "[epoch 10, batch   590] loss: 0.600\n",
      "Training Completed.\n"
     ]
    }
   ],
   "source": [
    "# - train() \n",
    "epochs = 10\n",
    "trainer.train(task=task,\n",
    "        epochs = epochs, \n",
    "        batch_count_print_avg_loss = 10,\n",
    "        loc_encoder = loc_encoder,\n",
    "        dataloader = train_loader,\n",
    "        decoder = decoder,\n",
    "        criterion = criterion,\n",
    "        optimizer = optimizer,\n",
    "        device = device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d618589a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-1 Accuracy on 816 test images: 83.09%\n",
      "Top-3 Accuracy on 816 test images: 96.81%\n",
      "MRR on 816 test images: 0.8994\n"
     ]
    }
   ],
   "source": [
    "# - test\n",
    "loc_encoder.eval()\n",
    "decoder.eval()\n",
    "\n",
    "total = 0\n",
    "correct_top1 = 0\n",
    "correct_top3 = 0\n",
    "mrr_sum = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for img_b, loc_b, y_b in test_loader:\n",
    "        img_b, loc_b, y_b = img_b.to(device), loc_b.to(device), y_b.to(device)\n",
    "\n",
    "        img_embedding = img_b\n",
    "        loc_embedding = trainer.forward_with_np_array(batch_data=loc_b, model=loc_encoder)\n",
    "\n",
    "        loc_img_interaction_embedding = torch.mul(loc_embedding, img_embedding)\n",
    "        logits = decoder(loc_img_interaction_embedding)\n",
    "\n",
    "        # Top-1\n",
    "        pred = logits.argmax(dim=1)\n",
    "        y_b = y_b.argmax(dim=1)\n",
    "\n",
    "        # Top-3 accuracy\n",
    "        top3_idx = logits.topk(3, dim=1).indices                    # [B, 3]\n",
    "        correct_top3 += (top3_idx == y_b.unsqueeze(1)).any(dim=1).sum().item()\n",
    "\n",
    "        # MRR (full ranking over all classes)\n",
    "        ranking = logits.argsort(dim=1, descending=True)             # [B, C]\n",
    "        positions = ranking.argsort(dim=1)                           # [B, C] where positions[b, c] = rank index (0-based)\n",
    "        true_pos0 = positions.gather(1, y_b.view(-1, 1)).squeeze(1)  # [B]\n",
    "        mrr_sum += (1.0 / (true_pos0.float() + 1.0)).sum().item()\n",
    "\n",
    "        total += y_b.size(0)\n",
    "        correct_top1 += (pred == y_b).sum().item()\n",
    "\n",
    "top1_acc = 100.0 * correct_top1 / total if total else 0.0\n",
    "top3_acc = 100.0 * correct_top3 / total if total else 0.0\n",
    "mrr = mrr_sum / total if total else 0.0\n",
    "\n",
    "print(f\"Top-1 Accuracy on {total} test images: {top1_acc:.2f}%\")\n",
    "print(f\"Top-3 Accuracy on {total} test images: {top3_acc:.2f}%\")\n",
    "print(f\"MRR on {total} test images: {mrr:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fd204f9",
   "metadata": {},
   "source": [
    "**Model saving**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "005c3426",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "def save_model(loc_encoder, decoder, optimizer, epoch, path):\n",
    "    path = Path(path)\n",
    "    path.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    torch.save({\n",
    "        \"epoch\": epoch,\n",
    "        \"loc_encoder\": loc_encoder.state_dict(),\n",
    "        \"decoder\": decoder.state_dict(),\n",
    "        \"optimizer\": optimizer.state_dict(),\n",
    "    }, path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c5c03132",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_model(\n",
    "    loc_encoder=loc_encoder,\n",
    "    decoder=decoder,\n",
    "    optimizer=optimizer,\n",
    "    epoch=epochs,\n",
    "    path=\"TorchSpatial/checkpoints/final.pt\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a96c917e",
   "metadata": {},
   "source": [
    "**Use Saved Models**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fc7b5677",
   "metadata": {},
   "outputs": [],
   "source": [
    "loc_encoder = get_loc_encoder(name = \"Space2Vec-grid\", overrides = {\"coord_dim\": coord_dim, \"spa_embed_dim\": loc_dim, \"device\": device}) # \"device\": device is needed if you defined device = 'cpu' above and don't have cuda setup to prevent \"AssertionError: Torch not compiled with CUDA enabled\", because the default is device=\"cuda\"\n",
    "decoder = premade_models.ThreeLayerMLP(input_dim = embed_dim, hidden_dim = 1024, category_count = num_classes).to(device)\n",
    "optimizer = Adam(params = list(loc_encoder.ffn.parameters()) + list(decoder.parameters()), lr = 1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "138d31fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt = torch.load(\"TorchSpatial/checkpoints/final.pt\", map_location=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f185eda8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loc_encoder.load_state_dict(ckpt[\"loc_encoder\"])\n",
    "decoder.load_state_dict(ckpt[\"decoder\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f79c7dee",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer.load_state_dict(ckpt[\"optimizer\"])\n",
    "start_epoch = ckpt[\"epoch\"] + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4e30dda1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-1 Accuracy on 816 test images: 83.09%\n",
      "Top-3 Accuracy on 816 test images: 96.81%\n",
      "MRR on 816 test images: 0.8994\n"
     ]
    }
   ],
   "source": [
    "# - test\n",
    "loc_encoder.eval()\n",
    "decoder.eval()\n",
    "\n",
    "total = 0\n",
    "correct_top1 = 0\n",
    "correct_top3 = 0\n",
    "mrr_sum = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for img_b, loc_b, y_b in test_loader:\n",
    "        img_b, loc_b, y_b = img_b.to(device), loc_b.to(device), y_b.to(device)\n",
    "\n",
    "        img_embedding = img_b\n",
    "        loc_embedding = trainer.forward_with_np_array(batch_data=loc_b, model=loc_encoder)\n",
    "\n",
    "        loc_img_interaction_embedding = torch.mul(loc_embedding, img_embedding)\n",
    "        logits = decoder(loc_img_interaction_embedding)\n",
    "\n",
    "        # Top-1\n",
    "        pred = logits.argmax(dim=1)\n",
    "        y_b = y_b.argmax(dim=1)\n",
    "\n",
    "        # Top-3 accuracy\n",
    "        top3_idx = logits.topk(3, dim=1).indices                    # [B, 3]\n",
    "        correct_top3 += (top3_idx == y_b.unsqueeze(1)).any(dim=1).sum().item()\n",
    "\n",
    "        # MRR (full ranking over all classes)\n",
    "        ranking = logits.argsort(dim=1, descending=True)             # [B, C]\n",
    "        positions = ranking.argsort(dim=1)                           # [B, C] where positions[b, c] = rank index (0-based)\n",
    "        true_pos0 = positions.gather(1, y_b.view(-1, 1)).squeeze(1)  # [B]\n",
    "        mrr_sum += (1.0 / (true_pos0.float() + 1.0)).sum().item()\n",
    "\n",
    "        total += y_b.size(0)\n",
    "        correct_top1 += (pred == y_b).sum().item()\n",
    "\n",
    "top1_acc = 100.0 * correct_top1 / total if total else 0.0\n",
    "top3_acc = 100.0 * correct_top3 / total if total else 0.0\n",
    "mrr = mrr_sum / total if total else 0.0\n",
    "\n",
    "print(f\"Top-1 Accuracy on {total} test images: {top1_acc:.2f}%\")\n",
    "print(f\"Top-3 Accuracy on {total} test images: {top3_acc:.2f}%\")\n",
    "print(f\"MRR on {total} test images: {mrr:.4f}\")\n",
    "\n",
    "# Results below match the final model pre-saving"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.13.2)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
