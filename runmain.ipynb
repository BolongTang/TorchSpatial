{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6a3f5aa7",
   "metadata": {},
   "source": [
    "**Put and run this notebook in the directory which contains TorchSpatial, because TorchSpatial will be used as a package. Relative imports are used within the package**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5433dc4d",
   "metadata": {},
   "source": [
    "**Model Training and Testing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "400ace9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim import Adam\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "15013057",
   "metadata": {},
   "outputs": [],
   "source": [
    "import TorchSpatial.modules.trainer as trainer\n",
    "from TorchSpatial.modules.encoder_selector import get_loc_encoder\n",
    "import TorchSpatial.modules.model as premade_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c50dc1c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/bolongtang/Downloads/TorchSpatial/modules/trainer.py\n"
     ]
    }
   ],
   "source": [
    "import importlib\n",
    "print(trainer.__file__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "669ae1f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'TorchSpatial.modules.model' from '/Users/bolongtang/Downloads/TorchSpatial/modules/model.py'>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# For easy reloading, bypassing cache in case trainer.py gets edited\n",
    "importlib.reload(trainer) \n",
    "\n",
    "importlib.reload(premade_models)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d979d3fa",
   "metadata": {},
   "source": [
    "**Import Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "385de89a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import TorchSpatial.utils.datasets as data_import\n",
    "import importlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f4c0523e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'TorchSpatial.utils.datasets' from '/Users/bolongtang/Downloads/TorchSpatial/utils/datasets.py'>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importlib.reload(data_import)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "86fbd409",
   "metadata": {},
   "outputs": [],
   "source": [
    "# - elevation dataset\n",
    "dataset = \"mosaiks_elevation\" \n",
    "task = \"Regression\" # \"Classification\" or \"Regression\"\n",
    "N = 19924\n",
    "device = \"cpu\"\n",
    "num_classes = 1 # 1 for regression\n",
    "img_dim = loc_dim = embed_dim = 2048 # birdsnap embedding count\n",
    "coord_dim = 2 #lonlat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e33a882a",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\"dataset\": dataset, \"regress_dataset\": [dataset]}\n",
    "train_remove_invalid = False\n",
    "eval_remove_invalid = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d083fc6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = data_import.load_dataset(params = params,\n",
    "    eval_split = \"train\",\n",
    "    train_remove_invalid = train_remove_invalid,\n",
    "    eval_remove_invalid = eval_remove_invalid,\n",
    "    load_cnn_predictions=True,\n",
    "    load_cnn_features=True,\n",
    "    load_cnn_features_train=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e2e4d6a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = data_import.load_dataset(params = params,\n",
    "    eval_split = \"test\",\n",
    "    train_remove_invalid = train_remove_invalid,\n",
    "    eval_remove_invalid = eval_remove_invalid,\n",
    "    load_cnn_predictions=True,\n",
    "    load_cnn_features=True,\n",
    "    load_cnn_features_train=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6eda68cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train_locs': array([[  41.77756 ,   39.75818 ],\n",
       "        [  28.294346,   12.246856],\n",
       "        [ 145.11217 ,  -41.215046],\n",
       "        ...,\n",
       "        [-102.722855,   60.976524],\n",
       "        [ -10.351114,   21.973127],\n",
       "        [-123.078514,   53.51189 ]], shape=(19924, 2), dtype=float32),\n",
       " 'val_locs': array([[ 45.923065,  33.360394],\n",
       "        [ 78.96314 ,  37.159798],\n",
       "        [124.10919 ,  40.032883],\n",
       "        ...,\n",
       "        [ 43.719475,  19.045477],\n",
       "        [-62.08039 , -11.030687],\n",
       "        [ 80.90506 ,  55.102493]], shape=(19924, 2), dtype=float32),\n",
       " 'train_labels': array([2120.29427785,  541.21146495,  244.59355366, ...,  420.89562191,\n",
       "         369.87917377,  739.34824927], shape=(19924,)),\n",
       " 'val_labels': array([ 114.9841604 , 1769.09281109,   72.95645193, ..., 1372.25071236,\n",
       "         167.19592743,  137.47612588], shape=(19924,)),\n",
       " 'train_feats': array([[7.09883804e+01, 1.05888466e+02, 1.13701385e+02, ...,\n",
       "         1.69064121e+01, 1.89716518e-02, 1.50931213e+02],\n",
       "        [1.07514885e+02, 8.81267471e+01, 1.50932510e+02, ...,\n",
       "         7.88689957e+01, 1.21732302e+01, 2.74826263e+02],\n",
       "        [1.05499008e+02, 8.17148666e+01, 1.09653793e+02, ...,\n",
       "         3.08204517e+01, 6.96213531e+00, 1.64113373e+02],\n",
       "        ...,\n",
       "        [3.25212364e+01, 2.85426483e+01, 3.49231644e+01, ...,\n",
       "         6.92408419e+00, 3.98559153e-01, 5.00585518e+01],\n",
       "        [7.24560547e+01, 1.06811310e+02, 8.51421738e+01, ...,\n",
       "         3.83987117e+00, 1.07380794e-02, 6.51109161e+01],\n",
       "        [1.52765274e+02, 7.64962921e+01, 1.98380142e+02, ...,\n",
       "         1.66265076e+02, 9.42128372e+01, 3.87543762e+02]],\n",
       "       shape=(19924, 2048)),\n",
       " 'val_feats': array([[1.66266876e+02, 1.72375732e+02, 1.58753799e+02, ...,\n",
       "         2.97512245e+00, 2.99801846e-04, 1.26311043e+02],\n",
       "        [1.11996651e+02, 9.85718079e+01, 1.35491180e+02, ...,\n",
       "         5.79941139e+01, 1.71740472e+00, 2.29780334e+02],\n",
       "        [9.77017441e+01, 4.74136772e+01, 9.53912354e+01, ...,\n",
       "         9.85031128e+01, 4.51617851e+01, 1.93205200e+02],\n",
       "        ...,\n",
       "        [9.42996902e+01, 1.05029388e+02, 1.01215843e+02, ...,\n",
       "         7.47219849e+00, 8.68869945e-03, 1.15224548e+02],\n",
       "        [1.16503021e+02, 3.54493141e+01, 8.22008743e+01, ...,\n",
       "         1.04434891e+02, 2.91199913e+01, 1.95801895e+02],\n",
       "        [1.44835022e+02, 8.83570862e+01, 1.77683380e+02, ...,\n",
       "         8.41711960e+01, 4.93771362e+00, 3.25791443e+02]],\n",
       "       shape=(19924, 2048))}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fa91751a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train_locs': array([[ 142.49539 ,   59.577072],\n",
       "        [ -53.238483,   48.464687],\n",
       "        [  32.825478,   62.949966],\n",
       "        ...,\n",
       "        [  64.63981 ,   26.615644],\n",
       "        [-121.90786 ,   53.281975],\n",
       "        [  28.404524,   47.151432]], shape=(19924, 2), dtype=float32),\n",
       " 'val_locs': array([[ -9.910397,  29.639257],\n",
       "        [104.30443 ,  26.591017],\n",
       "        [ 86.16613 ,  36.983994],\n",
       "        ...,\n",
       "        [116.83735 ,  46.03483 ],\n",
       "        [ 66.92603 ,  50.512848],\n",
       "        [ 20.499146,  66.660126]], shape=(4981, 2), dtype=float32),\n",
       " 'train_labels': array([ 169.26715921,  100.24858892,  272.4877168 , ..., 1101.6675496 ,\n",
       "        1130.8944546 ,   95.21605049], shape=(19924,)),\n",
       " 'val_labels': array([ 245.05220033, 2063.15844245, 5047.17393594, ...,  995.83144531,\n",
       "         369.2575738 ,  373.21170245], shape=(4981,)),\n",
       " 'train_feats': array([[1.90226273e+02, 1.51160278e+02, 2.42391922e+02, ...,\n",
       "         8.84392319e+01, 3.88942289e+00, 3.69282593e+02],\n",
       "        [1.42180939e+02, 8.47650833e+01, 1.13715553e+02, ...,\n",
       "         3.95357704e+01, 9.77875292e-03, 2.00422394e+02],\n",
       "        [2.32022552e+02, 1.48862411e+02, 3.34890076e+02, ...,\n",
       "         1.52379593e+02, 3.14372635e+01, 5.74101013e+02],\n",
       "        ...,\n",
       "        [2.63044067e+02, 1.91116623e+02, 3.38398438e+02, ...,\n",
       "         8.35355988e+01, 2.84131393e-02, 4.56702240e+02],\n",
       "        [1.91184402e+02, 1.13596298e+02, 2.15887680e+02, ...,\n",
       "         8.69261475e+01, 2.48254891e-02, 3.43561310e+02],\n",
       "        [8.87347260e+01, 7.32874680e+01, 1.14138954e+02, ...,\n",
       "         5.98106270e+01, 1.63522606e+01, 1.85286728e+02]],\n",
       "       shape=(19924, 2048)),\n",
       " 'val_feats': array([[7.49020233e+01, 9.73154831e+01, 1.16687073e+02, ...,\n",
       "         2.42927322e+01, 8.69234920e-01, 1.46488953e+02],\n",
       "        [1.13567062e+02, 8.43854980e+01, 1.13183167e+02, ...,\n",
       "         1.27836601e+02, 7.56773605e+01, 2.21638535e+02],\n",
       "        [1.03949448e+02, 1.13399452e+02, 1.06600845e+02, ...,\n",
       "         9.20466042e+00, 6.70745643e-03, 1.08556076e+02],\n",
       "        ...,\n",
       "        [8.81532364e+01, 3.32148590e+01, 4.46956863e+01, ...,\n",
       "         6.52264881e+00, 1.46844452e-02, 5.20248451e+01],\n",
       "        [9.19743652e+01, 1.23673851e+02, 1.03012634e+02, ...,\n",
       "         2.61643124e+00, 3.89271625e-03, 6.86253738e+01],\n",
       "        [2.23524353e+02, 1.42021973e+02, 2.65561401e+02, ...,\n",
       "         1.17327103e+02, 1.45779684e-01, 4.50954803e+02]],\n",
       "       shape=(4981, 2048))}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f15dba9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_tr = train_data[\"val_feats\"] # shape=(19924, 2048)\n",
    "loc_tr = train_data[\"val_locs\"] # shape=(19924, 2)\n",
    "y_tr = train_data[\"val_labels\"] # shape=(19924,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ac80406e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(19924, 2048) (19924, 2) (19924,)\n"
     ]
    }
   ],
   "source": [
    "print(img_tr.shape, loc_tr.shape, y_tr.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "527be13a",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_te = test_data[\"val_feats\"] # shape=(4981, 2048)\n",
    "loc_te = test_data[\"val_locs\"] # shape=(4981, 2)\n",
    "y_te = test_data[\"val_labels\"] # shape=(4981,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "76ae39a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4981, 2048) (4981, 2) (4981,)\n"
     ]
    }
   ],
   "source": [
    "print(img_te.shape, loc_te.shape, y_te.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2f912810",
   "metadata": {},
   "outputs": [],
   "source": [
    "if task == \"Classification\":\n",
    "    embed_dim = img_dim \n",
    "elif task == \"Regression\": \n",
    "    embed_dim = img_dim + loc_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0fea3507",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = list(zip(img_tr, loc_tr, y_tr))\n",
    "test_data  = list(zip(img_te, loc_te, y_te))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "398a5485",
   "metadata": {},
   "outputs": [],
   "source": [
    "# - Dataloader (loads image embeddings)\n",
    "train_loader = DataLoader(train_data, batch_size=32, shuffle=True)\n",
    "train_loader2 = DataLoader(train_data, batch_size=32, shuffle=True) # For demonstration only; used below to not iterate through the actual train_loader, which is an iterator and each row only be accessed once per refill\n",
    "test_loader  = DataLoader(test_data, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce1ed806",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 2048]) <class 'torch.Tensor'> tensor([[8.6213e+01, 1.7304e+02, 1.3278e+02,  ..., 1.4729e+01, 2.6515e-03,\n",
      "         1.4438e+02],\n",
      "        [1.3062e+02, 5.3233e+01, 4.8042e+01,  ..., 2.7860e+01, 3.5443e+00,\n",
      "         7.8044e+01],\n",
      "        [9.9071e+01, 3.2816e+01, 7.3385e+01,  ..., 2.6624e+01, 1.9787e-02,\n",
      "         1.1771e+02],\n",
      "        ...,\n",
      "        [1.5240e+02, 1.0245e+02, 1.7994e+02,  ..., 7.6576e+01, 1.1382e+00,\n",
      "         3.0921e+02],\n",
      "        [1.6880e+02, 2.3754e+02, 1.9398e+02,  ..., 1.7495e+00, 4.0724e-04,\n",
      "         6.9914e+01],\n",
      "        [1.0461e+02, 8.0904e+01, 1.0658e+02,  ..., 2.0065e+01, 9.8399e-02,\n",
      "         1.3300e+02]], dtype=torch.float64)\n",
      "torch.Size([32, 2]) <class 'torch.Tensor'> tensor([[  47.4380,  -16.8295],\n",
      "        [ -71.2115,    3.7447],\n",
      "        [-100.5744,   54.4031],\n",
      "        [ 117.2918,    5.9539],\n",
      "        [  90.6559,   56.6701],\n",
      "        [  25.4848,    6.7068],\n",
      "        [  -9.1805,   11.1950],\n",
      "        [ 139.2313,   52.3583],\n",
      "        [  77.1865,   15.5750],\n",
      "        [  24.2039,   16.9236],\n",
      "        [  -4.1811,   31.1949],\n",
      "        [  24.5482,   46.8886],\n",
      "        [  58.9931,   61.8073],\n",
      "        [ -92.3522,   44.8952],\n",
      "        [  39.3123,    0.7449],\n",
      "        [  58.4284,   54.7384],\n",
      "        [  99.8697,    1.5573],\n",
      "        [  69.5428,   25.5271],\n",
      "        [  74.2805,   52.5345],\n",
      "        [-104.4444,   39.0345],\n",
      "        [  33.1147,    2.3281],\n",
      "        [  32.6740,    2.8372],\n",
      "        [  33.0458,   40.8608],\n",
      "        [ -49.5475,   67.9973],\n",
      "        [  16.7117,  -12.7423],\n",
      "        [ -66.7079,  -31.4887],\n",
      "        [ -88.7025,   53.4791],\n",
      "        [-163.6934,   67.1837],\n",
      "        [-102.5300,   39.7688],\n",
      "        [ -80.0396,   32.9684],\n",
      "        [  -0.8481,   31.2891],\n",
      "        [-118.7815,   35.2824]])\n",
      "torch.Size([32]) <class 'torch.Tensor'> tensor([ 548.8181,  181.1684,  276.8798,   28.2836,  204.7726,  671.6802,\n",
      "         386.5931,  568.8976,  395.6713,  670.6690,  728.0056,  503.4630,\n",
      "         503.3656,  370.2921,  224.5026,  752.4610,   53.2385,   16.2470,\n",
      "         106.2807, 2060.6567, 1094.0115,  994.7015, 1429.5631,  429.2863,\n",
      "        1622.5727,  504.5178,  209.2591,    3.0050, 1241.7958,    6.3296,\n",
      "         704.3871,  205.1462], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "for img_b, loc_b, y_b in train_loader2:\n",
    "    print(img_b.shape, type(img_b), img_b) \n",
    "    print(loc_b.shape, type(loc_b), loc_b) \n",
    "    print(y_b.shape, type(y_b), y_b) \n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5f19a9f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# - location encoder\n",
    "# Allowed: Space2Vec-grid, Space2Vec-theory, xyz, NeRF, Sphere2Vec-sphereC, Sphere2Vec-sphereC+, Sphere2Vec-sphereM, Sphere2Vec-sphereM+, Sphere2Vec-dfs, rbf, rff, wrap, wrap_ffn, tile_ffn\n",
    "# overrides is a dictionary that allows overriding specific params. \n",
    "# ex. loc_encoder = get_loc_encoder(name = \"Space2Vec-grid\", overrides = {\"max_radius\":7800, \"min_radius\":15, \"spa_embed_dim\":2048, \"device\": device})\n",
    "loc_encoder_name = \"Space2Vec-grid\"\n",
    "loc_encoder = get_loc_encoder(name = loc_encoder_name, overrides = {\"coord_dim\": coord_dim, \"spa_embed_dim\": loc_dim, \"device\": device}) # \"device\": device is needed if you defined device = 'cpu' above and don't have cuda setup to prevent \"AssertionError: Torch not compiled with CUDA enabled\", because the default is device=\"cuda\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2868bf79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# - model\n",
    "decoder = premade_models.ThreeLayerMLP(input_dim = embed_dim, hidden_dim = 1024, category_count = num_classes).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f552086",
   "metadata": {},
   "outputs": [],
   "source": [
    "# - model\n",
    "# - Criterion\n",
    "if task == \"Classification\":\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "elif task == \"Regression\":\n",
    "    criterion = nn.MSELoss()\n",
    "# - Optimizer\n",
    "optimizer = Adam(params = list(loc_encoder.ffn.parameters()) + list(decoder.parameters()), lr = 1e-3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7fd5dec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 1, batch    10] loss: 6.232\n",
      "[epoch 1, batch    20] loss: 6.220\n",
      "[epoch 1, batch    30] loss: 6.206\n",
      "[epoch 1, batch    40] loss: 6.181\n",
      "[epoch 1, batch    50] loss: 6.165\n",
      "[epoch 1, batch    60] loss: 6.120\n",
      "[epoch 1, batch    70] loss: 6.003\n",
      "[epoch 1, batch    80] loss: 5.686\n",
      "[epoch 1, batch    90] loss: 5.132\n",
      "[epoch 1, batch   100] loss: 4.786\n",
      "[epoch 1, batch   110] loss: 4.281\n",
      "[epoch 1, batch   120] loss: 3.864\n",
      "[epoch 1, batch   130] loss: 3.558\n",
      "[epoch 1, batch   140] loss: 3.019\n",
      "[epoch 1, batch   150] loss: 2.591\n",
      "[epoch 1, batch   160] loss: 2.612\n",
      "[epoch 1, batch   170] loss: 2.294\n",
      "[epoch 1, batch   180] loss: 2.232\n",
      "[epoch 1, batch   190] loss: 1.723\n",
      "[epoch 1, batch   200] loss: 1.918\n",
      "[epoch 1, batch   210] loss: 1.940\n",
      "[epoch 1, batch   220] loss: 1.802\n",
      "[epoch 1, batch   230] loss: 1.652\n",
      "[epoch 1, batch   240] loss: 1.749\n",
      "[epoch 1, batch   250] loss: 1.551\n",
      "[epoch 1, batch   260] loss: 1.652\n",
      "[epoch 1, batch   270] loss: 1.425\n",
      "[epoch 1, batch   280] loss: 1.441\n",
      "[epoch 1, batch   290] loss: 1.326\n",
      "[epoch 1, batch   300] loss: 1.521\n",
      "[epoch 1, batch   310] loss: 1.343\n",
      "[epoch 1, batch   320] loss: 1.353\n",
      "[epoch 1, batch   330] loss: 1.193\n",
      "[epoch 1, batch   340] loss: 1.291\n",
      "[epoch 1, batch   350] loss: 1.347\n",
      "[epoch 1, batch   360] loss: 1.262\n",
      "[epoch 1, batch   370] loss: 1.219\n",
      "[epoch 1, batch   380] loss: 1.301\n",
      "[epoch 1, batch   390] loss: 1.142\n",
      "[epoch 1, batch   400] loss: 1.116\n",
      "[epoch 1, batch   410] loss: 1.179\n",
      "[epoch 1, batch   420] loss: 1.203\n",
      "[epoch 1, batch   430] loss: 1.189\n",
      "[epoch 1, batch   440] loss: 1.211\n",
      "[epoch 1, batch   450] loss: 1.128\n",
      "[epoch 1, batch   460] loss: 1.187\n",
      "[epoch 1, batch   470] loss: 1.035\n",
      "[epoch 2, batch    10] loss: 0.969\n",
      "[epoch 2, batch    20] loss: 1.028\n",
      "[epoch 2, batch    30] loss: 1.163\n",
      "[epoch 2, batch    40] loss: 1.057\n",
      "[epoch 2, batch    50] loss: 1.017\n",
      "[epoch 2, batch    60] loss: 1.065\n",
      "[epoch 2, batch    70] loss: 0.849\n",
      "[epoch 2, batch    80] loss: 0.921\n",
      "[epoch 2, batch    90] loss: 1.015\n",
      "[epoch 2, batch   100] loss: 0.931\n",
      "[epoch 2, batch   110] loss: 1.029\n",
      "[epoch 2, batch   120] loss: 1.052\n",
      "[epoch 2, batch   130] loss: 0.873\n",
      "[epoch 2, batch   140] loss: 1.065\n",
      "[epoch 2, batch   150] loss: 0.977\n",
      "[epoch 2, batch   160] loss: 0.937\n",
      "[epoch 2, batch   170] loss: 0.993\n",
      "[epoch 2, batch   180] loss: 0.960\n",
      "[epoch 2, batch   190] loss: 1.053\n",
      "[epoch 2, batch   200] loss: 0.874\n",
      "[epoch 2, batch   210] loss: 1.006\n",
      "[epoch 2, batch   220] loss: 0.917\n",
      "[epoch 2, batch   230] loss: 0.828\n",
      "[epoch 2, batch   240] loss: 0.913\n",
      "[epoch 2, batch   250] loss: 1.006\n",
      "[epoch 2, batch   260] loss: 0.954\n",
      "[epoch 2, batch   270] loss: 0.765\n",
      "[epoch 2, batch   280] loss: 1.053\n",
      "[epoch 2, batch   290] loss: 0.922\n",
      "[epoch 2, batch   300] loss: 1.052\n",
      "[epoch 2, batch   310] loss: 0.837\n",
      "[epoch 2, batch   320] loss: 0.853\n",
      "[epoch 2, batch   330] loss: 0.824\n",
      "[epoch 2, batch   340] loss: 0.911\n",
      "[epoch 2, batch   350] loss: 0.958\n",
      "[epoch 2, batch   360] loss: 0.987\n",
      "[epoch 2, batch   370] loss: 0.968\n",
      "[epoch 2, batch   380] loss: 0.861\n",
      "[epoch 2, batch   390] loss: 0.860\n",
      "[epoch 2, batch   400] loss: 0.958\n",
      "[epoch 2, batch   410] loss: 0.971\n",
      "[epoch 2, batch   420] loss: 0.946\n",
      "[epoch 2, batch   430] loss: 0.850\n",
      "[epoch 2, batch   440] loss: 0.866\n",
      "[epoch 2, batch   450] loss: 0.946\n",
      "[epoch 2, batch   460] loss: 0.932\n",
      "[epoch 2, batch   470] loss: 0.728\n",
      "[epoch 3, batch    10] loss: 0.783\n",
      "[epoch 3, batch    20] loss: 0.893\n",
      "[epoch 3, batch    30] loss: 0.866\n",
      "[epoch 3, batch    40] loss: 0.724\n",
      "[epoch 3, batch    50] loss: 0.885\n",
      "[epoch 3, batch    60] loss: 0.998\n",
      "[epoch 3, batch    70] loss: 0.916\n",
      "[epoch 3, batch    80] loss: 0.770\n",
      "[epoch 3, batch    90] loss: 0.862\n",
      "[epoch 3, batch   100] loss: 0.793\n",
      "[epoch 3, batch   110] loss: 0.845\n",
      "[epoch 3, batch   120] loss: 0.836\n",
      "[epoch 3, batch   130] loss: 0.758\n",
      "[epoch 3, batch   140] loss: 0.837\n",
      "[epoch 3, batch   150] loss: 0.831\n",
      "[epoch 3, batch   160] loss: 0.881\n",
      "[epoch 3, batch   170] loss: 0.768\n",
      "[epoch 3, batch   180] loss: 0.867\n",
      "[epoch 3, batch   190] loss: 0.889\n",
      "[epoch 3, batch   200] loss: 0.854\n",
      "[epoch 3, batch   210] loss: 0.798\n",
      "[epoch 3, batch   220] loss: 0.905\n",
      "[epoch 3, batch   230] loss: 0.804\n",
      "[epoch 3, batch   240] loss: 0.836\n",
      "[epoch 3, batch   250] loss: 0.834\n",
      "[epoch 3, batch   260] loss: 0.847\n",
      "[epoch 3, batch   270] loss: 0.668\n",
      "[epoch 3, batch   280] loss: 0.725\n",
      "[epoch 3, batch   290] loss: 0.797\n",
      "[epoch 3, batch   300] loss: 0.945\n",
      "[epoch 3, batch   310] loss: 0.857\n",
      "[epoch 3, batch   320] loss: 0.821\n",
      "[epoch 3, batch   330] loss: 0.833\n",
      "[epoch 3, batch   340] loss: 0.827\n",
      "[epoch 3, batch   350] loss: 0.789\n",
      "[epoch 3, batch   360] loss: 0.873\n",
      "[epoch 3, batch   370] loss: 0.780\n",
      "[epoch 3, batch   380] loss: 0.776\n",
      "[epoch 3, batch   390] loss: 0.927\n",
      "[epoch 3, batch   400] loss: 0.813\n",
      "[epoch 3, batch   410] loss: 0.750\n",
      "[epoch 3, batch   420] loss: 0.696\n",
      "[epoch 3, batch   430] loss: 0.844\n",
      "[epoch 3, batch   440] loss: 0.757\n",
      "[epoch 3, batch   450] loss: 0.662\n",
      "[epoch 3, batch   460] loss: 0.871\n",
      "[epoch 3, batch   470] loss: 0.718\n",
      "[epoch 4, batch    10] loss: 0.859\n",
      "[epoch 4, batch    20] loss: 0.776\n",
      "[epoch 4, batch    30] loss: 0.663\n",
      "[epoch 4, batch    40] loss: 0.706\n",
      "[epoch 4, batch    50] loss: 0.766\n",
      "[epoch 4, batch    60] loss: 0.786\n",
      "[epoch 4, batch    70] loss: 0.725\n",
      "[epoch 4, batch    80] loss: 0.806\n",
      "[epoch 4, batch    90] loss: 0.774\n",
      "[epoch 4, batch   100] loss: 0.869\n",
      "[epoch 4, batch   110] loss: 0.587\n",
      "[epoch 4, batch   120] loss: 0.720\n",
      "[epoch 4, batch   130] loss: 0.688\n",
      "[epoch 4, batch   140] loss: 0.775\n",
      "[epoch 4, batch   150] loss: 0.832\n",
      "[epoch 4, batch   160] loss: 0.810\n",
      "[epoch 4, batch   170] loss: 0.727\n",
      "[epoch 4, batch   180] loss: 0.765\n",
      "[epoch 4, batch   190] loss: 0.692\n",
      "[epoch 4, batch   200] loss: 0.808\n",
      "[epoch 4, batch   210] loss: 0.837\n",
      "[epoch 4, batch   220] loss: 0.845\n",
      "[epoch 4, batch   230] loss: 0.779\n",
      "[epoch 4, batch   240] loss: 0.798\n",
      "[epoch 4, batch   250] loss: 0.876\n",
      "[epoch 4, batch   260] loss: 0.795\n",
      "[epoch 4, batch   270] loss: 0.757\n",
      "[epoch 4, batch   280] loss: 0.651\n",
      "[epoch 4, batch   290] loss: 0.792\n",
      "[epoch 4, batch   300] loss: 0.710\n",
      "[epoch 4, batch   310] loss: 0.787\n",
      "[epoch 4, batch   320] loss: 0.687\n",
      "[epoch 4, batch   330] loss: 0.823\n",
      "[epoch 4, batch   340] loss: 0.767\n",
      "[epoch 4, batch   350] loss: 0.790\n",
      "[epoch 4, batch   360] loss: 0.760\n",
      "[epoch 4, batch   370] loss: 0.715\n",
      "[epoch 4, batch   380] loss: 0.867\n",
      "[epoch 4, batch   390] loss: 0.828\n",
      "[epoch 4, batch   400] loss: 0.780\n",
      "[epoch 4, batch   410] loss: 0.729\n",
      "[epoch 4, batch   420] loss: 0.724\n",
      "[epoch 4, batch   430] loss: 0.764\n",
      "[epoch 4, batch   440] loss: 0.769\n",
      "[epoch 4, batch   450] loss: 0.637\n",
      "[epoch 4, batch   460] loss: 0.688\n",
      "[epoch 4, batch   470] loss: 0.759\n",
      "[epoch 5, batch    10] loss: 0.698\n",
      "[epoch 5, batch    20] loss: 0.823\n",
      "[epoch 5, batch    30] loss: 0.720\n",
      "[epoch 5, batch    40] loss: 0.642\n",
      "[epoch 5, batch    50] loss: 0.751\n",
      "[epoch 5, batch    60] loss: 0.763\n",
      "[epoch 5, batch    70] loss: 0.693\n",
      "[epoch 5, batch    80] loss: 0.689\n",
      "[epoch 5, batch    90] loss: 0.836\n",
      "[epoch 5, batch   100] loss: 0.754\n",
      "[epoch 5, batch   110] loss: 0.692\n",
      "[epoch 5, batch   120] loss: 0.757\n",
      "[epoch 5, batch   130] loss: 0.718\n",
      "[epoch 5, batch   140] loss: 0.649\n",
      "[epoch 5, batch   150] loss: 0.681\n",
      "[epoch 5, batch   160] loss: 0.732\n",
      "[epoch 5, batch   170] loss: 0.658\n",
      "[epoch 5, batch   180] loss: 0.806\n",
      "[epoch 5, batch   190] loss: 0.629\n",
      "[epoch 5, batch   200] loss: 0.852\n",
      "[epoch 5, batch   210] loss: 0.660\n",
      "[epoch 5, batch   220] loss: 0.862\n",
      "[epoch 5, batch   230] loss: 0.707\n",
      "[epoch 5, batch   240] loss: 0.867\n",
      "[epoch 5, batch   250] loss: 0.868\n",
      "[epoch 5, batch   260] loss: 0.737\n",
      "[epoch 5, batch   270] loss: 0.885\n",
      "[epoch 5, batch   280] loss: 0.644\n",
      "[epoch 5, batch   290] loss: 0.638\n",
      "[epoch 5, batch   300] loss: 0.748\n",
      "[epoch 5, batch   310] loss: 0.744\n",
      "[epoch 5, batch   320] loss: 0.622\n",
      "[epoch 5, batch   330] loss: 0.730\n",
      "[epoch 5, batch   340] loss: 0.679\n",
      "[epoch 5, batch   350] loss: 0.746\n",
      "[epoch 5, batch   360] loss: 0.673\n",
      "[epoch 5, batch   370] loss: 0.790\n",
      "[epoch 5, batch   380] loss: 0.661\n",
      "[epoch 5, batch   390] loss: 0.750\n",
      "[epoch 5, batch   400] loss: 0.653\n",
      "[epoch 5, batch   410] loss: 0.754\n",
      "[epoch 5, batch   420] loss: 0.729\n",
      "[epoch 5, batch   430] loss: 0.690\n",
      "[epoch 5, batch   440] loss: 0.837\n",
      "[epoch 5, batch   450] loss: 0.675\n",
      "[epoch 5, batch   460] loss: 0.730\n",
      "[epoch 5, batch   470] loss: 0.808\n",
      "[epoch 6, batch    10] loss: 0.708\n",
      "[epoch 6, batch    20] loss: 0.812\n",
      "[epoch 6, batch    30] loss: 0.756\n",
      "[epoch 6, batch    40] loss: 0.552\n",
      "[epoch 6, batch    50] loss: 0.647\n",
      "[epoch 6, batch    60] loss: 0.642\n",
      "[epoch 6, batch    70] loss: 0.624\n",
      "[epoch 6, batch    80] loss: 0.769\n",
      "[epoch 6, batch    90] loss: 0.689\n",
      "[epoch 6, batch   100] loss: 0.706\n",
      "[epoch 6, batch   110] loss: 0.753\n",
      "[epoch 6, batch   120] loss: 0.609\n",
      "[epoch 6, batch   130] loss: 0.642\n",
      "[epoch 6, batch   140] loss: 0.721\n",
      "[epoch 6, batch   150] loss: 0.677\n",
      "[epoch 6, batch   160] loss: 0.856\n",
      "[epoch 6, batch   170] loss: 0.759\n",
      "[epoch 6, batch   180] loss: 0.800\n",
      "[epoch 6, batch   190] loss: 0.654\n",
      "[epoch 6, batch   200] loss: 0.616\n",
      "[epoch 6, batch   210] loss: 0.773\n",
      "[epoch 6, batch   220] loss: 0.682\n",
      "[epoch 6, batch   230] loss: 0.774\n",
      "[epoch 6, batch   240] loss: 0.667\n",
      "[epoch 6, batch   250] loss: 0.656\n",
      "[epoch 6, batch   260] loss: 0.660\n",
      "[epoch 6, batch   270] loss: 0.758\n",
      "[epoch 6, batch   280] loss: 0.737\n",
      "[epoch 6, batch   290] loss: 0.767\n",
      "[epoch 6, batch   300] loss: 0.653\n",
      "[epoch 6, batch   310] loss: 0.812\n",
      "[epoch 6, batch   320] loss: 0.701\n",
      "[epoch 6, batch   330] loss: 0.787\n",
      "[epoch 6, batch   340] loss: 0.624\n",
      "[epoch 6, batch   350] loss: 0.733\n",
      "[epoch 6, batch   360] loss: 0.725\n",
      "[epoch 6, batch   370] loss: 0.636\n",
      "[epoch 6, batch   380] loss: 0.696\n",
      "[epoch 6, batch   390] loss: 0.616\n",
      "[epoch 6, batch   400] loss: 0.707\n",
      "[epoch 6, batch   410] loss: 0.698\n",
      "[epoch 6, batch   420] loss: 0.859\n",
      "[epoch 6, batch   430] loss: 0.613\n",
      "[epoch 6, batch   440] loss: 0.721\n",
      "[epoch 6, batch   450] loss: 0.691\n",
      "[epoch 6, batch   460] loss: 0.698\n",
      "[epoch 6, batch   470] loss: 0.670\n",
      "[epoch 7, batch    10] loss: 0.760\n",
      "[epoch 7, batch    20] loss: 0.709\n",
      "[epoch 7, batch    30] loss: 0.727\n",
      "[epoch 7, batch    40] loss: 0.737\n",
      "[epoch 7, batch    50] loss: 0.699\n",
      "[epoch 7, batch    60] loss: 0.737\n",
      "[epoch 7, batch    70] loss: 0.655\n",
      "[epoch 7, batch    80] loss: 0.684\n",
      "[epoch 7, batch    90] loss: 0.644\n",
      "[epoch 7, batch   100] loss: 0.667\n",
      "[epoch 7, batch   110] loss: 0.585\n",
      "[epoch 7, batch   120] loss: 0.792\n",
      "[epoch 7, batch   130] loss: 0.789\n",
      "[epoch 7, batch   140] loss: 0.610\n",
      "[epoch 7, batch   150] loss: 0.623\n",
      "[epoch 7, batch   160] loss: 0.736\n",
      "[epoch 7, batch   170] loss: 0.657\n",
      "[epoch 7, batch   180] loss: 0.675\n",
      "[epoch 7, batch   190] loss: 0.647\n",
      "[epoch 7, batch   200] loss: 0.685\n",
      "[epoch 7, batch   210] loss: 0.727\n",
      "[epoch 7, batch   220] loss: 0.666\n",
      "[epoch 7, batch   230] loss: 0.569\n",
      "[epoch 7, batch   240] loss: 0.611\n",
      "[epoch 7, batch   250] loss: 0.679\n",
      "[epoch 7, batch   260] loss: 0.719\n",
      "[epoch 7, batch   270] loss: 0.624\n",
      "[epoch 7, batch   280] loss: 0.758\n",
      "[epoch 7, batch   290] loss: 0.680\n",
      "[epoch 7, batch   300] loss: 0.642\n",
      "[epoch 7, batch   310] loss: 0.770\n",
      "[epoch 7, batch   320] loss: 0.718\n",
      "[epoch 7, batch   330] loss: 0.612\n",
      "[epoch 7, batch   340] loss: 0.609\n",
      "[epoch 7, batch   350] loss: 0.673\n",
      "[epoch 7, batch   360] loss: 0.602\n",
      "[epoch 7, batch   370] loss: 0.590\n",
      "[epoch 7, batch   380] loss: 0.574\n",
      "[epoch 7, batch   390] loss: 0.656\n",
      "[epoch 7, batch   400] loss: 0.721\n",
      "[epoch 7, batch   410] loss: 0.726\n",
      "[epoch 7, batch   420] loss: 0.691\n",
      "[epoch 7, batch   430] loss: 0.837\n",
      "[epoch 7, batch   440] loss: 0.761\n",
      "[epoch 7, batch   450] loss: 0.797\n",
      "[epoch 7, batch   460] loss: 0.839\n",
      "[epoch 7, batch   470] loss: 0.645\n",
      "[epoch 8, batch    10] loss: 0.658\n",
      "[epoch 8, batch    20] loss: 0.649\n",
      "[epoch 8, batch    30] loss: 0.645\n",
      "[epoch 8, batch    40] loss: 0.687\n",
      "[epoch 8, batch    50] loss: 0.623\n",
      "[epoch 8, batch    60] loss: 0.707\n",
      "[epoch 8, batch    70] loss: 0.619\n",
      "[epoch 8, batch    80] loss: 0.681\n",
      "[epoch 8, batch    90] loss: 0.645\n",
      "[epoch 8, batch   100] loss: 0.607\n",
      "[epoch 8, batch   110] loss: 0.637\n",
      "[epoch 8, batch   120] loss: 0.723\n",
      "[epoch 8, batch   130] loss: 0.688\n",
      "[epoch 8, batch   140] loss: 0.735\n",
      "[epoch 8, batch   150] loss: 0.666\n",
      "[epoch 8, batch   160] loss: 0.642\n",
      "[epoch 8, batch   170] loss: 0.752\n",
      "[epoch 8, batch   180] loss: 0.640\n",
      "[epoch 8, batch   190] loss: 0.601\n",
      "[epoch 8, batch   200] loss: 0.624\n",
      "[epoch 8, batch   210] loss: 0.689\n",
      "[epoch 8, batch   220] loss: 0.603\n",
      "[epoch 8, batch   230] loss: 0.680\n",
      "[epoch 8, batch   240] loss: 0.720\n",
      "[epoch 8, batch   250] loss: 0.843\n",
      "[epoch 8, batch   260] loss: 0.592\n",
      "[epoch 8, batch   270] loss: 0.673\n",
      "[epoch 8, batch   280] loss: 0.664\n",
      "[epoch 8, batch   290] loss: 0.681\n",
      "[epoch 8, batch   300] loss: 0.548\n",
      "[epoch 8, batch   310] loss: 0.731\n",
      "[epoch 8, batch   320] loss: 0.677\n",
      "[epoch 8, batch   330] loss: 0.705\n",
      "[epoch 8, batch   340] loss: 0.702\n",
      "[epoch 8, batch   350] loss: 0.693\n",
      "[epoch 8, batch   360] loss: 0.682\n",
      "[epoch 8, batch   370] loss: 0.521\n",
      "[epoch 8, batch   380] loss: 0.665\n",
      "[epoch 8, batch   390] loss: 0.592\n",
      "[epoch 8, batch   400] loss: 0.669\n",
      "[epoch 8, batch   410] loss: 0.709\n",
      "[epoch 8, batch   420] loss: 0.692\n",
      "[epoch 8, batch   430] loss: 0.706\n",
      "[epoch 8, batch   440] loss: 0.646\n",
      "[epoch 8, batch   450] loss: 0.589\n",
      "[epoch 8, batch   460] loss: 0.686\n",
      "[epoch 8, batch   470] loss: 0.571\n",
      "[epoch 9, batch    10] loss: 0.611\n",
      "[epoch 9, batch    20] loss: 0.611\n",
      "[epoch 9, batch    30] loss: 0.630\n",
      "[epoch 9, batch    40] loss: 0.717\n",
      "[epoch 9, batch    50] loss: 0.646\n",
      "[epoch 9, batch    60] loss: 0.675\n",
      "[epoch 9, batch    70] loss: 0.679\n",
      "[epoch 9, batch    80] loss: 0.668\n",
      "[epoch 9, batch    90] loss: 0.626\n",
      "[epoch 9, batch   100] loss: 0.540\n",
      "[epoch 9, batch   110] loss: 0.676\n",
      "[epoch 9, batch   120] loss: 0.672\n",
      "[epoch 9, batch   130] loss: 0.620\n",
      "[epoch 9, batch   140] loss: 0.808\n",
      "[epoch 9, batch   150] loss: 0.722\n",
      "[epoch 9, batch   160] loss: 0.648\n",
      "[epoch 9, batch   170] loss: 0.577\n",
      "[epoch 9, batch   180] loss: 0.547\n",
      "[epoch 9, batch   190] loss: 0.584\n",
      "[epoch 9, batch   200] loss: 0.690\n",
      "[epoch 9, batch   210] loss: 0.620\n",
      "[epoch 9, batch   220] loss: 0.786\n",
      "[epoch 9, batch   230] loss: 0.629\n",
      "[epoch 9, batch   240] loss: 0.596\n",
      "[epoch 9, batch   250] loss: 0.694\n",
      "[epoch 9, batch   260] loss: 0.590\n",
      "[epoch 9, batch   270] loss: 0.677\n",
      "[epoch 9, batch   280] loss: 0.595\n",
      "[epoch 9, batch   290] loss: 0.647\n",
      "[epoch 9, batch   300] loss: 0.718\n",
      "[epoch 9, batch   310] loss: 0.643\n",
      "[epoch 9, batch   320] loss: 0.625\n",
      "[epoch 9, batch   330] loss: 0.582\n",
      "[epoch 9, batch   340] loss: 0.581\n",
      "[epoch 9, batch   350] loss: 0.632\n",
      "[epoch 9, batch   360] loss: 0.718\n",
      "[epoch 9, batch   370] loss: 0.684\n",
      "[epoch 9, batch   380] loss: 0.769\n",
      "[epoch 9, batch   390] loss: 0.561\n",
      "[epoch 9, batch   400] loss: 0.663\n",
      "[epoch 9, batch   410] loss: 0.777\n",
      "[epoch 9, batch   420] loss: 0.659\n",
      "[epoch 9, batch   430] loss: 0.548\n",
      "[epoch 9, batch   440] loss: 0.776\n",
      "[epoch 9, batch   450] loss: 0.697\n",
      "[epoch 9, batch   460] loss: 0.650\n",
      "[epoch 9, batch   470] loss: 0.629\n",
      "[epoch 10, batch    10] loss: 0.716\n",
      "[epoch 10, batch    20] loss: 0.611\n",
      "[epoch 10, batch    30] loss: 0.648\n",
      "[epoch 10, batch    40] loss: 0.728\n",
      "[epoch 10, batch    50] loss: 0.565\n",
      "[epoch 10, batch    60] loss: 0.727\n",
      "[epoch 10, batch    70] loss: 0.633\n",
      "[epoch 10, batch    80] loss: 0.584\n",
      "[epoch 10, batch    90] loss: 0.532\n",
      "[epoch 10, batch   100] loss: 0.646\n",
      "[epoch 10, batch   110] loss: 0.530\n",
      "[epoch 10, batch   120] loss: 0.634\n",
      "[epoch 10, batch   130] loss: 0.688\n",
      "[epoch 10, batch   140] loss: 0.659\n",
      "[epoch 10, batch   150] loss: 0.645\n",
      "[epoch 10, batch   160] loss: 0.586\n",
      "[epoch 10, batch   170] loss: 0.725\n",
      "[epoch 10, batch   180] loss: 0.635\n",
      "[epoch 10, batch   190] loss: 0.618\n",
      "[epoch 10, batch   200] loss: 0.591\n",
      "[epoch 10, batch   210] loss: 0.654\n",
      "[epoch 10, batch   220] loss: 0.603\n",
      "[epoch 10, batch   230] loss: 0.630\n",
      "[epoch 10, batch   240] loss: 0.644\n",
      "[epoch 10, batch   250] loss: 0.668\n",
      "[epoch 10, batch   260] loss: 0.530\n",
      "[epoch 10, batch   270] loss: 0.631\n",
      "[epoch 10, batch   280] loss: 0.794\n",
      "[epoch 10, batch   290] loss: 0.695\n",
      "[epoch 10, batch   300] loss: 0.613\n",
      "[epoch 10, batch   310] loss: 0.770\n",
      "[epoch 10, batch   320] loss: 0.689\n",
      "[epoch 10, batch   330] loss: 0.666\n",
      "[epoch 10, batch   340] loss: 0.664\n",
      "[epoch 10, batch   350] loss: 0.629\n",
      "[epoch 10, batch   360] loss: 0.673\n",
      "[epoch 10, batch   370] loss: 0.516\n",
      "[epoch 10, batch   380] loss: 0.589\n",
      "[epoch 10, batch   390] loss: 0.654\n",
      "[epoch 10, batch   400] loss: 0.635\n",
      "[epoch 10, batch   410] loss: 0.621\n",
      "[epoch 10, batch   420] loss: 0.561\n",
      "[epoch 10, batch   430] loss: 0.698\n",
      "[epoch 10, batch   440] loss: 0.711\n",
      "[epoch 10, batch   450] loss: 0.758\n",
      "[epoch 10, batch   460] loss: 0.571\n",
      "[epoch 10, batch   470] loss: 0.691\n",
      "Training Completed.\n"
     ]
    }
   ],
   "source": [
    "# - train() \n",
    "epochs = 10\n",
    "trainer.train(task=task,\n",
    "        epochs = epochs, \n",
    "        batch_count_print_avg_loss = 10,\n",
    "        loc_encoder = loc_encoder,\n",
    "        dataloader = train_loader,\n",
    "        decoder = decoder,\n",
    "        criterion = criterion,\n",
    "        optimizer = optimizer,\n",
    "        device = device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d618589a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-1 Accuracy on 3827 test images: 90.04%\n",
      "Top-3 Accuracy on 3827 test images: 98.77%\n",
      "MRR on 3827 test images: 0.9430\n"
     ]
    }
   ],
   "source": [
    "# - test\n",
    "loc_encoder.eval()\n",
    "decoder.eval()\n",
    "\n",
    "total = 0\n",
    "correct_top1 = 0\n",
    "correct_top3 = 0\n",
    "mrr_sum = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for img_b, loc_b, y_b in test_loader:\n",
    "        img_b, loc_b, y_b = img_b.to(device), loc_b.to(device), y_b.to(device)\n",
    "\n",
    "        img_embedding = img_b\n",
    "        loc_embedding = trainer.forward_with_np_array(batch_data=loc_b, model=loc_encoder)\n",
    "\n",
    "        if task == \"Classification\":\n",
    "            loc_img_interaction_embedding = torch.mul(loc_embedding, img_embedding)\n",
    "            logits = decoder(loc_img_interaction_embedding)\n",
    "\n",
    "            # Top-1\n",
    "            pred = logits.argmax(dim=1)\n",
    "            y_b = y_b.argmax(dim=1)\n",
    "\n",
    "            # Top-3 accuracy\n",
    "            top3_idx = logits.topk(3, dim=1).indices                    # [B, 3]\n",
    "            correct_top3 += (top3_idx == y_b.unsqueeze(1)).any(dim=1).sum().item()\n",
    "\n",
    "            # MRR (full ranking over all classes)\n",
    "            ranking = logits.argsort(dim=1, descending=True)             # [B, C]\n",
    "            positions = ranking.argsort(dim=1)                           # [B, C] where positions[b, c] = rank index (0-based)\n",
    "            true_pos0 = positions.gather(1, y_b.view(-1, 1)).squeeze(1)  # [B]\n",
    "            mrr_sum += (1.0 / (true_pos0.float() + 1.0)).sum().item()\n",
    "\n",
    "            total += y_b.size(0)\n",
    "            correct_top1 += (pred == y_b).sum().item()\n",
    "        \n",
    "        elif task == \"Regression\":\n",
    "            loc_img_concat_embedding = torch.cat((loc_embedding, img_embedding), dim = 1)\n",
    "            yhat = decoder(loc_img_concat_embedding)\n",
    "\n",
    "            # r-square\n",
    "            # Compute per-sample mean over feature dimension\n",
    "            y_mean = torch.mean(y_b, dim=1, keepdim=True)          # (B, 1)\n",
    "\n",
    "            ss_res = torch.sum((y_b - yhat) ** 2, dim=1)           # (B,)\n",
    "            ss_tot = torch.sum((y_b - y_mean) ** 2, dim=1)         # (B,)\n",
    "\n",
    "            r2 = 1 - ss_res / ss_tot                               # (B,)\n",
    "            r2 = torch.mean(r2)                                    # scalar\n",
    "\n",
    "            # MAE\n",
    "            mae = torch.mean(torch.abs(yhat - y_b))\n",
    "\n",
    "            # RMSE\n",
    "            rmse = torch.sqrt(torch.mean((yhat - y_b) ** 2))\n",
    "\n",
    "            total += y_b.size(0)\n",
    "\n",
    "if task == \"Classification\":\n",
    "    top1_acc = 100.0 * correct_top1 / total if total else 0.0\n",
    "    top3_acc = 100.0 * correct_top3 / total if total else 0.0\n",
    "    mrr = mrr_sum / total if total else 0.0\n",
    "\n",
    "    print(f\"Top-1 Accuracy on {total} test images: {top1_acc:.2f}%\")\n",
    "    print(f\"Top-3 Accuracy on {total} test images: {top3_acc:.2f}%\")\n",
    "    print(f\"MRR on {total} test images: {mrr:.4f}\")\n",
    "elif task == \"Regression\":\n",
    "    print(f\"r-square on {total} test images: {r2:.2f}%\")\n",
    "    print(f\"MAE of pred on {total} test images: {mae:.2f}%\")\n",
    "    print(f\"RMSE of pred on {total} test images: {rmse:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fd204f9",
   "metadata": {},
   "source": [
    "**Model saving**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "005c3426",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "def save_model(loc_encoder, decoder, optimizer, epoch, path):\n",
    "    path = Path(path)\n",
    "    path.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    torch.save({\n",
    "        \"epoch\": epoch,\n",
    "        \"loc_encoder\": loc_encoder.state_dict(),\n",
    "        \"decoder\": decoder.state_dict(),\n",
    "        \"optimizer\": optimizer.state_dict(),\n",
    "    }, path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5c03132",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_model(\n",
    "    loc_encoder=loc_encoder,\n",
    "    decoder=decoder,\n",
    "    optimizer=optimizer,\n",
    "    epoch=epochs,\n",
    "    path=\"TorchSpatial/checkpoints/final.pt\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a96c917e",
   "metadata": {},
   "source": [
    "**Use Saved Models**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc7b5677",
   "metadata": {},
   "outputs": [],
   "source": [
    "loc_encoder = get_loc_encoder(name = \"Space2Vec-grid\", overrides = {\"coord_dim\": coord_dim, \"spa_embed_dim\": loc_dim, \"device\": device}) # \"device\": device is needed if you defined device = 'cpu' above and don't have cuda setup to prevent \"AssertionError: Torch not compiled with CUDA enabled\", because the default is device=\"cuda\"\n",
    "decoder = premade_models.ThreeLayerMLP(input_dim = embed_dim, hidden_dim = 1024, category_count = num_classes).to(device)\n",
    "optimizer = Adam(params = list(loc_encoder.ffn.parameters()) + list(decoder.parameters()), lr = 1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "138d31fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt = torch.load(\"TorchSpatial/checkpoints/final.pt\", map_location=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f185eda8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loc_encoder.load_state_dict(ckpt[\"loc_encoder\"])\n",
    "decoder.load_state_dict(ckpt[\"decoder\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f79c7dee",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer.load_state_dict(ckpt[\"optimizer\"])\n",
    "start_epoch = ckpt[\"epoch\"] + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4e30dda1",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'loc_encoder' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# - test\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[43mloc_encoder\u001b[49m.eval()\n\u001b[32m      3\u001b[39m decoder.eval()\n\u001b[32m      5\u001b[39m total = \u001b[32m0\u001b[39m\n",
      "\u001b[31mNameError\u001b[39m: name 'loc_encoder' is not defined"
     ]
    }
   ],
   "source": [
    "# - test\n",
    "loc_encoder.eval()\n",
    "decoder.eval()\n",
    "\n",
    "total = 0\n",
    "correct_top1 = 0\n",
    "correct_top3 = 0\n",
    "mrr_sum = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for img_b, loc_b, y_b in test_loader:\n",
    "        img_b, loc_b, y_b = img_b.to(device), loc_b.to(device), y_b.to(device)\n",
    "\n",
    "        img_embedding = img_b\n",
    "        loc_embedding = trainer.forward_with_np_array(batch_data=loc_b, model=loc_encoder)\n",
    "\n",
    "        loc_img_interaction_embedding = torch.mul(loc_embedding, img_embedding)\n",
    "        logits = decoder(loc_img_interaction_embedding)\n",
    "\n",
    "        # Top-1\n",
    "        pred = logits.argmax(dim=1)\n",
    "        y_b = y_b.argmax(dim=1)\n",
    "\n",
    "        # Top-3 accuracy\n",
    "        top3_idx = logits.topk(3, dim=1).indices                    # [B, 3]\n",
    "        correct_top3 += (top3_idx == y_b.unsqueeze(1)).any(dim=1).sum().item()\n",
    "\n",
    "        # MRR (full ranking over all classes)\n",
    "        ranking = logits.argsort(dim=1, descending=True)             # [B, C]\n",
    "        positions = ranking.argsort(dim=1)                           # [B, C] where positions[b, c] = rank index (0-based)\n",
    "        true_pos0 = positions.gather(1, y_b.view(-1, 1)).squeeze(1)  # [B]\n",
    "        mrr_sum += (1.0 / (true_pos0.float() + 1.0)).sum().item()\n",
    "\n",
    "        total += y_b.size(0)\n",
    "        correct_top1 += (pred == y_b).sum().item()\n",
    "\n",
    "top1_acc = 100.0 * correct_top1 / total if total else 0.0\n",
    "top3_acc = 100.0 * correct_top3 / total if total else 0.0\n",
    "mrr = mrr_sum / total if total else 0.0\n",
    "\n",
    "print(f\"Top-1 Accuracy on {total} test images: {top1_acc:.2f}%\")\n",
    "print(f\"Top-3 Accuracy on {total} test images: {top3_acc:.2f}%\")\n",
    "print(f\"MRR on {total} test images: {mrr:.4f}\")\n",
    "\n",
    "# Results below match the final model pre-saving"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.13.2)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
